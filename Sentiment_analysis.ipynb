{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "VtV5gvuLRe81"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75MYYecNG1-2",
        "colab_type": "text"
      },
      "source": [
        "##Start setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykzUH7wLzW_y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "070f6fa8-283f-468d-d540-ee57d852f836"
      },
      "source": [
        "# google drive settings \n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMVVGkkszPzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# google drive settings \n",
        "%%capture\n",
        "%cd /content/gdrive/My\\ Drive/NLP"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR8wzTnyTGgC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5903b1a-d47e-42d6-f377-62af3a0640ab"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from prettytable import PrettyTable\n",
        "import keras"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fricmldxUsbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1_95qj5oQJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture \n",
        "!pip install scikit-plot"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtV5gvuLRe81",
        "colab_type": "text"
      },
      "source": [
        "## Support utility functions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMd8EqaKTb_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "! python -m spacy download it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuSMZTC5Rn5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import re\n",
        "import it_core_news_sm\n",
        "nlp =it_core_news_sm.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUscTytITSo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_tweet(text):   \n",
        "  #remove urls \n",
        "  urls_pattern = 'http\\S+'\n",
        "  clean_version = re.sub(urls_pattern, ' ', text)\n",
        "\n",
        "  #replace hashtag symbol with whitespace\n",
        "  hashtag_pattern = '#(\\w+)'\n",
        "  clean_version = re.sub(hashtag_pattern, ' ', clean_version)\n",
        "\n",
        "  #replace - with whitespace\n",
        "  clean_version = clean_version.replace('-', ' ')\n",
        "\n",
        "  clean_version = clean_version.replace('_', ' ')\n",
        "\n",
        "  #replace \\ with whitespace\n",
        "  clean_version = clean_version.replace('\\'' , ' ')\n",
        "\n",
        "  #remove \\n \n",
        "  clean_version = clean_version.replace('\\n', ' ')\n",
        "\n",
        "  #remove emoji \n",
        "  emoji_pattern = re.compile(pattern = \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags = re.UNICODE)\n",
        "  clean_version = emoji_pattern.sub(' ',clean_version)\n",
        "\n",
        "  #remove numbers \n",
        "  numbers_pattern = '\\d+'\n",
        "  clean_version = re.sub(numbers_pattern, ' ', clean_version)\n",
        "\n",
        "  #remove punctuation (remove also @)\n",
        "  punt_pattern = '[^\\w\\s]'\n",
        "  clean_version = re.sub(punt_pattern,' ',clean_version)\n",
        "\n",
        "  # remove multiple whitespace \n",
        "  clean_version = re.sub(' +', ' ', clean_version )\n",
        "\n",
        "  return clean_version.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFtrCGjmzHWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# retrieve italian stopwords from file \n",
        "stop_word_file = open(\"tweet_data/italian_stop_words.txt\", \"r\")\n",
        "stopwords_italian = stop_word_file.read().split('\\n')\n",
        "set_word = set(stopwords_italian) #transform it to set to allow faster evaluation\n",
        "\n",
        "def lemmatize_text(text, stopword_list = set_word): \n",
        "  final_words = [] \n",
        "  lemmas = [token.lemma_ for token in nlp(text) \n",
        "              if token.pos_ in {'ADJ', 'ADV', 'NOUN', 'NUMERAL', 'NUM', 'PROPN','VERB'}]\n",
        "  for word in lemmas:  \n",
        "    if word not in stopword_list: \n",
        "      final_words.append(word)\n",
        "  return (\" \".join(final_words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuFRGpr6qvLN",
        "colab_type": "text"
      },
      "source": [
        "## Retrieve original dataset and preprocess them \n",
        "\n",
        "Dataset source [GitHub](https://github.com/charlesmalafosse/open-dataset-for-sentiment-analysis \n",
        ")\n",
        "\n",
        "To run only the fist time (the result of the preprocess phase is saved into new csv files) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMIJIglvQ8qY",
        "colab_type": "text"
      },
      "source": [
        "### First dataset with tweets about footbal players"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXZMOFHuS7R-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sport_sentiment = pd.read_csv('tweet_data/sentiment.csv', encoding='ISO-8859-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqWPucjoV91u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "955d2d62-dcec-4869-fc9d-a43466eb36b5"
      },
      "source": [
        "sport_sentiment.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(165815, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLH5gTXXTSwr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "85ef0189-9e0d-474a-81d8-07e9351ecdfc"
      },
      "source": [
        "sport_sentiment['sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NEUTRAL     135194\n",
              "POSITIVE     23552\n",
              "NEGATIVE      6542\n",
              "MIXED          527\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCb-SmY5TSh5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "d107ef5c-61ce-4c3e-d8ce-365a86b9a1cd"
      },
      "source": [
        "sport_sentiment.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_date_created</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>language</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>sentiment_score</th>\n",
              "      <th>cleaned_tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-12-10T10:45:40.865000</td>\n",
              "      <td>1072079899224100865</td>\n",
              "      <td>@juventusfc @G_Higuain Auguri pipita,sempre co...</td>\n",
              "      <td>it</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>{\"Neutral\":0.858726024627685546875,\"Negative\":...</td>\n",
              "      <td>juventusfc g higuain auguri pipita sempre con...</td>\n",
              "      <td>juventusfc g higuain auguri pipita sempre con...</td>\n",
              "      <td>juventusfc higuain augurio pipita</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-06-30T18:41:02.817000</td>\n",
              "      <td>1013130303454498817</td>\n",
              "      <td>@realvarriale @massimozampini @KMbappe @G_Higu...</td>\n",
              "      <td>it</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>{\"Neutral\":0.973993778228759765625,\"Negative\":...</td>\n",
              "      <td>realvarriale massimozampini kmbappe g higuain...</td>\n",
              "      <td>realvarriale massimozampini kmbappe g higuain...</td>\n",
              "      <td>realvarriale massimozampini kmbappe higuain pa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           tweet_date_created  ...                                         clean_text\n",
              "0  2018-12-10T10:45:40.865000  ...                  juventusfc higuain augurio pipita\n",
              "1  2018-06-30T18:41:02.817000  ...  realvarriale massimozampini kmbappe higuain pa...\n",
              "\n",
              "[2 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcB5UQInTStq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c4d6d664-b55b-4d06-bbd1-8298de4ff540"
      },
      "source": [
        "%%time\n",
        "sport_sentiment['clean_tweet'] = sport_sentiment['tweet_text'].apply(clean_tweet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.54 s, sys: 14.1 ms, total: 3.55 s\n",
            "Wall time: 3.56 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRMO7khNz17x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1406c8ff-8960-4162-b88c-e497c571a6ce"
      },
      "source": [
        "%%time\n",
        "sport_sentiment['clean_text'] = sport_sentiment['clean_tweet'].apply(lemmatize_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 25min 41s, sys: 2.37 s, total: 25min 43s\n",
            "Wall time: 25min 45s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEFC3m-F0FOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "columns = ['tweet_text', 'clean_tweet', 'clean_text', 'sentiment', 'sentiment_score']\n",
        "sport_sentiment[columns].to_csv('tweet_data/sport_player_new.csv', index=False, quoting=csv.QUOTE_ALL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LgybNEOIkcy",
        "colab_type": "text"
      },
      "source": [
        "### Second dataset about football teams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R31CaMQIaHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sport_teams = pd.read_csv('tweet_data/sport_sentiment_team_1.csv', encoding='ISO-8859-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNJAA4wjIZ_6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a5a6d6a-805e-4a2e-d898-ec2eb6cdfcaf"
      },
      "source": [
        "sport_teams.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(259569, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh5MZR65I-0-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "80bbd535-e3b4-48d9-9775-d289c9cb2bf7"
      },
      "source": [
        "sport_teams['sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NEUTRAL     226868\n",
              "POSITIVE     22883\n",
              "NEGATIVE      9441\n",
              "MIXED          377\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iMBKVP6I-yv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "9c2fa6a5-d596-44e5-d796-3842807454c4"
      },
      "source": [
        "sport_teams.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_date_created</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>language</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>sentiment_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-12-10T10:45:40.865000</td>\n",
              "      <td>1072079899224100865</td>\n",
              "      <td>@juventusfc @G_Higuain Auguri pipita,sempre co...</td>\n",
              "      <td>it</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>{\"Neutral\":0.858726024627685546875,\"Negative\":...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-12-26T19:40:44.308000</td>\n",
              "      <td>1078012758069858308</td>\n",
              "      <td>@OfficialASRoma @D_10Perotti @Hyundai_Italia S...</td>\n",
              "      <td>it</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>{\"Neutral\":0.9844334125518798828125,\"Negative\"...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           tweet_date_created  ...                                    sentiment_score\n",
              "0  2018-12-10T10:45:40.865000  ...  {\"Neutral\":0.858726024627685546875,\"Negative\":...\n",
              "1  2018-12-26T19:40:44.308000  ...  {\"Neutral\":0.9844334125518798828125,\"Negative\"...\n",
              "\n",
              "[2 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps2BRWXCI-wP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6093fc86-bd03-4f39-b353-2acad3315c66"
      },
      "source": [
        "%%time\n",
        "sport_teams['clean_tweet'] = sport_teams['tweet_text'].apply(clean_tweet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5.34 s, sys: 66.9 ms, total: 5.41 s\n",
            "Wall time: 5.41 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nURJ59mgI-uR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "59ab9bf8-5ccf-4db6-b405-e4afe4aed137"
      },
      "source": [
        "%%time\n",
        "sport_teams['clean_text'] = sport_teams['clean_tweet'].apply(lemmatize_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 40min 51s, sys: 3.72 s, total: 40min 55s\n",
            "Wall time: 40min 58s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDA_-ZfrI-re",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "columns = ['tweet_text', 'clean_tweet', 'clean_text', 'sentiment', 'sentiment_score']\n",
        "sport_teams[columns].to_csv('tweet_data/sport_teams_new.csv', index=False, quoting=csv.QUOTE_ALL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_b_wNYqI-nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYx6J3cZVCHu",
        "colab_type": "text"
      },
      "source": [
        "### Create global sport dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XfuDajgU9G4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "player_sentiment = pd.read_csv('tweet_data/sport_player_new.csv', encoding='ISO-8859-1')\n",
        "team_sentiment = pd.read_csv('tweet_data/sport_teams_new.csv', encoding='ISO-8859-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uoU3PPMU89W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# drop nan \n",
        "player_sentiment = player_sentiment[player_sentiment.clean_text.isna() == False ]\n",
        "team_sentiment = team_sentiment[team_sentiment.clean_text.isna() == False ]\n",
        "\n",
        "#drop \"mixed\" sentiment \n",
        "player_red = player_sentiment[player_sentiment.sentiment!='MIXED']\n",
        "team_red = team_sentiment[team_sentiment.sentiment!='MIXED']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RtXdLfEK5yF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "189e8a26-a182-412c-dd48-9c4a7cc89d42"
      },
      "source": [
        "player_red.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(165281, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGoWEvohQtTB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "b7752889-25e2-45ef-c995-daedfa578e67"
      },
      "source": [
        "player_red_counts = player_red['sentiment'].value_counts()\n",
        "player_red_counts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NEUTRAL     135187\n",
              "POSITIVE     23552\n",
              "NEGATIVE      6542\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIGKuvZSQ161",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "e681696f-7843-4389-d12f-17220c74a8a6"
      },
      "source": [
        "print(\"neutral {}\".format(player_red_counts[0]/player_red.shape[0] *100))\n",
        "print(\"positive {}\".format(player_red_counts[1]/player_red.shape[0] *100))\n",
        "print(\"negative {}\".format(player_red_counts[2]/player_red.shape[0] *100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "neutral 81.79222052141505\n",
            "positive 14.249671771104966\n",
            "negative 3.958107707479989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdq7Po_oK77t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f1454a6-238a-443f-a95d-bf7b82d8b180"
      },
      "source": [
        "team_red.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(258354, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZkRTR3QQ8_k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "bf053173-ab70-45f0-b97f-b7f1c53c9256"
      },
      "source": [
        "team_red_counts = team_red['sentiment'].value_counts()\n",
        "team_red_counts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NEUTRAL     226102\n",
              "POSITIVE     22813\n",
              "NEGATIVE      9439\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPNYJRYeRBz1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "2782f921-bee3-401a-b1d5-acccdf420211"
      },
      "source": [
        "print(\"neutral {}\".format(team_red_counts[0]/team_red.shape[0] *100))\n",
        "print(\"positive {}\".format(team_red_counts[1]/team_red.shape[0] *100))\n",
        "print(\"negative {}\".format(team_red_counts[2]/team_red.shape[0] *100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "neutral 87.51635353042724\n",
            "positive 8.830132299093492\n",
            "negative 3.653514170479265\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzHyjiwK81p3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08e8238a-93ec-4b34-9fab-0acc31af1da3"
      },
      "source": [
        "# create global dataset \n",
        "sport_sentiment_full = pd.concat([player_red, team_red], ignore_index=True)\n",
        "sport_sentiment_full.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(423635, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qe1Xf0UICMJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "992c5fb6-a7d6-4dd7-dd89-66e4cc9c0073"
      },
      "source": [
        "sentiment_counts = sport_sentiment_full['sentiment'].value_counts()\n",
        "sentiment_counts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NEUTRAL     361289\n",
              "POSITIVE     46365\n",
              "NEGATIVE     15981\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4135A0xlLg27",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b30fe7e6-3b3e-4790-fa71-f1bbdba9b102"
      },
      "source": [
        "print(\"neutral {}\".format(sentiment_counts[0]/sport_sentiment_full.shape[0] *100))\n",
        "print(\"positive {}\".format(sentiment_counts[1]/sport_sentiment_full.shape[0] *100))\n",
        "print(\"negative {}\".format(sentiment_counts[2]/sport_sentiment_full.shape[0] *100))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "neutral 85.28308567516848\n",
            "positive 10.944563126276158\n",
            "negative 3.7723511985553597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoFPA2GoKWu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # create global balanced dataset\n",
        "# sport_sentiment = sport_sentiment_full.groupby('sentiment').apply(lambda x: x.sample(n=15981)).reset_index(drop = True)\n",
        "# sport_sentiment.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Huy3e6eOKj-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sport_sentiment['sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB6bTRs-rXWr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "4a51c44f-838a-445d-a63e-488fee55c51f"
      },
      "source": [
        "sport_sentiment_full.isna().any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweet_text         False\n",
              "clean_tweet        False\n",
              "clean_text         False\n",
              "sentiment          False\n",
              "sentiment_score    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMFBg6RpNsg9",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btqa1Q1wtMlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if already run, load train and test files\n",
        "train = pd.read_csv(\"tweet_data/train.csv\", lineterminator='\\n')\n",
        "test = pd.read_csv(\"tweet_data/test.csv\", lineterminator='\\n') \n",
        "train_under = pd.read_csv(\"tweet_data/train_under.csv\", lineterminator='\\n')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_AlSpL3WSUv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5acdfa46-a0b2-4467-ce97-dfdf4d16885d"
      },
      "source": [
        "# otherwise divide train and test \n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(sport_sentiment_full, test_size=0.33, random_state=42)\n",
        "print(\"Train\", train.shape)\n",
        "print(\"Test\", test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train (283835, 5)\n",
            "Test (139800, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy5DhsKQYCqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To run only the first time to save the train and test dataset\n",
        "# train.to_csv('tweet_data/train.csv', index = False)\n",
        "# test.to_csv('tweet_data/test.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPeH4LonIR4V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "f37b4339-5c3b-4cda-bb8c-a8c85372958c"
      },
      "source": [
        "train['sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NEUTRAL     242084\n",
              "POSITIVE     30994\n",
              "NEGATIVE     10757\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxNPJ30kPEQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# under-sampling --> the category with less instances is the negative one with 10757 rows \n",
        "train_under = train.groupby('sentiment').apply(lambda x: x.sample(n=10757)).reset_index(drop = True)\n",
        "# train_under.to_csv('tweet_data/train_under.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ2z7ZPYWWoq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5cf14294-209d-47ba-8f2a-487428f95994"
      },
      "source": [
        "train_under.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32271, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaL0AJeVWbD2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "7d64b3a6-5ae6-4c7f-de8c-988607ff0767"
      },
      "source": [
        "train_under['sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "POSITIVE    10757\n",
              "NEUTRAL     10757\n",
              "NEGATIVE    10757\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiYoTxOvTjj9",
        "colab_type": "text"
      },
      "source": [
        "## Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEzdCKqql1cG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the models (if already trained to avoid re-run all)\n",
        "from joblib import load\n",
        "logistic_under = load('tweet_data/models/logistic_under.joblib') \n",
        "logistic_over = load('tweet_data/models/logistic_over.joblib') \n",
        "logistic_original = load('tweet_data/models/logistic_original.joblib')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PorRgt5-spYU",
        "colab_type": "text"
      },
      "source": [
        "### Original dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeCurkjdssgn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2816491a-3063-49d9-9824-ef533fce9531"
      },
      "source": [
        "# transfrom label into numbers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labels2numbers = LabelEncoder()\n",
        "y_original = labels2numbers.fit_transform(train['sentiment'])\n",
        "print(labels2numbers.classes_)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NEGATIVE' 'NEUTRAL' 'POSITIVE']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bP3n89Rstx4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cf44151-afb2-44aa-fd1d-afe3f6a0a0f6"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,4), \n",
        "                             min_df=0.001, \n",
        "                             max_df=0.75)\n",
        "\n",
        "X_original = vectorizer.fit_transform(train['clean_text'])\n",
        "print(X_original.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(283835, 1578)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiWFLh9Ws12W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "22e7e322-6983-4255-e45c-71eb9b411084"
      },
      "source": [
        "# fitting the model \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_original = LogisticRegression(n_jobs=-1)\n",
        "%time logistic_original.fit(X_original, y_original)\n",
        "print(logistic_original)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 39.7 ms, sys: 126 ms, total: 166 ms\n",
            "Wall time: 12.8 s\n",
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Xim5JBPtDrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_X = vectorizer.transform(test['clean_text']) # transform text into word counts \n",
        "new_y = labels2numbers.transform(test['sentiment']) # transfrom label into numbers \n",
        "new_predictions = logistic_original.predict(new_X) # prediction using the logistic classifier "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Bg1Sj9-tW0Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4445f4ea-4f30-4875-9097-e0235ce1db77"
      },
      "source": [
        "new_X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(139800, 1578)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsPUhxzUtamW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "db1fe8bc-eeb6-4838-e814-705461a6d00e"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(new_y, new_predictions))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.18      0.28      5224\n",
            "           1       0.89      0.98      0.93    119205\n",
            "           2       0.70      0.34      0.45     15371\n",
            "\n",
            "    accuracy                           0.88    139800\n",
            "   macro avg       0.74      0.50      0.56    139800\n",
            "weighted avg       0.86      0.88      0.85    139800\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNlse0ejteNZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "c8f07408-fac9-4436-e84a-e1588faff7fd"
      },
      "source": [
        "# baseline, assign all tweets to the most frequent category (neutral)\n",
        "baseline_predictions =  [labels2numbers.transform(['NEUTRAL'])] * len(new_y)\n",
        "print(classification_report(new_y, baseline_predictions))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      5224\n",
            "           1       0.85      1.00      0.92    119205\n",
            "           2       0.00      0.00      0.00     15371\n",
            "\n",
            "    accuracy                           0.85    139800\n",
            "   macro avg       0.28      0.33      0.31    139800\n",
            "weighted avg       0.73      0.85      0.78    139800\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fEcL7-mlt2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed98e27f-97f8-4367-8981-bbedc862d327"
      },
      "source": [
        "# ROC curve \n",
        "from sklearn import metrics\n",
        "fpr_original, tpr_original, thresholds_original = metrics.roc_curve(new_y, new_predictions, pos_label=0)\n",
        "auc_original = np.trapz(tpr_original,fpr_original)\n",
        "print('AUC:', auc_original)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.3951397546554473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDcO1I5bqyf2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7145b688-a2af-4dae-a1b3-1ab8626a453e"
      },
      "source": [
        "# ROC curve \n",
        "from sklearn import metrics\n",
        "fpr_baseline, tpr_baseline, thresholds_baseline = metrics.roc_curve(new_y, baseline_predictions, pos_label=0)\n",
        "auc_baseline = np.trapz(tpr_baseline,fpr_baseline)\n",
        "print('AUC:', auc_baseline)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT9O77OnrLei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "c7f403dd-fdea-415e-dbd4-9dbe9ba89d9b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Print ROC curve\n",
        "plt.plot(fpr_original,tpr_original)\n",
        "plt.plot(fpr_baseline, tpr_baseline)\n",
        "plt.show() "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17dpRpLazN8f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a88a7de0-4608-4082-a34e-764cd09dfefb"
      },
      "source": [
        "# save the model \n",
        "from joblib import dump\n",
        "dump(logistic_original, 'tweet_data/models/logistic_original.joblib') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tweet_data/models/logistic_original.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5YJZcjFLn37",
        "colab_type": "text"
      },
      "source": [
        "### Under-sampling dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN0LE_fCUh9l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51ddf370-0cf0-45d3-b47a-4c6b0a35b93d"
      },
      "source": [
        "#transfrom label into numbers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labels2numbers = LabelEncoder()\n",
        "y_under = labels2numbers.fit_transform(train_under['sentiment'])\n",
        "print(labels2numbers.classes_)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NEGATIVE' 'NEUTRAL' 'POSITIVE']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNgvkL5gVL_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c23309e3-5388-45d1-e9d0-b9a1e30b2d95"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,4), \n",
        "                             min_df=0.001, \n",
        "                             max_df=0.75)\n",
        "\n",
        "X_under = vectorizer.fit_transform(train_under['clean_text'])\n",
        "print(X_under.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32271, 1610)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyrrixouVj9C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "0df6a49a-4c2d-41ea-9ef3-5b169b451c84"
      },
      "source": [
        "#fitting the model \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_under = LogisticRegression(n_jobs=-1, class_weight='balanced')\n",
        "%time logistic_under.fit(X_under, y_under)\n",
        "print(logistic_under)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 19.3 ms, sys: 58.8 ms, total: 78.1 ms\n",
            "Wall time: 2.56 s\n",
            "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=-1, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LylUnfdsVp_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_X = vectorizer.transform(test['clean_text']) # transform text into word counts \n",
        "new_y = labels2numbers.transform(test['sentiment']) # transfrom label into numbers \n",
        "new_predictions = logistic_under.predict(new_X) # prediction using the logistic classifier "
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn2tlVONSs_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db22cc53-2f1c-4632-e1f8-83fa162cfac9"
      },
      "source": [
        "new_X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(139800, 1610)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIzOlvsXXUjL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "b625f227-9911-4455-d50a-90c9ffeafa53"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(new_y, new_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.18      0.76      0.29      5224\n",
            "           1       0.95      0.70      0.81    119205\n",
            "           2       0.37      0.70      0.48     15371\n",
            "\n",
            "    accuracy                           0.70    139800\n",
            "   macro avg       0.50      0.72      0.53    139800\n",
            "weighted avg       0.86      0.70      0.75    139800\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8XHLcA6sUm7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "91940e63-e91a-4f21-8e97-6d6052ebaf5f"
      },
      "source": [
        "# ROC curve \n",
        "from sklearn import metrics\n",
        "fpr_under, tpr_under, thresholds_under = metrics.roc_curve(new_y, new_predictions, pos_label=0)\n",
        "auc_under = np.trapz(tpr_under,fpr_under)\n",
        "print('AUC:', auc_under)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.19211367574307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tz-TUv7sVl1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "3b5d82f6-cf00-46bf-a209-120c4b42b09d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Print ROC curve\n",
        "plt.plot(fpr_under,tpr_under)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9d9f6146a0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF6PmKtGSKqS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f2fb564-f706-461b-fdb4-d019e1d746ac"
      },
      "source": [
        "# save the model \n",
        "from joblib import dump\n",
        "dump(logistic_under, 'tweet_data/models/logistic_under.joblib') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tweet_data/models/logistic_under.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0Kbz5x9BDcW",
        "colab_type": "text"
      },
      "source": [
        "### Over-sampling dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM2VZmDuIOfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install imbalanced-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNH7m10FAj4v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a6bd35b9-f4c8-49dd-a651-e5b0881691c8"
      },
      "source": [
        "#transfrom label into numbers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labels2numbers = LabelEncoder()\n",
        "y = labels2numbers.fit_transform(train['sentiment'])\n",
        "print(labels2numbers.classes_)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,4), \n",
        "                             min_df=0.001, \n",
        "                             max_df=0.75)\n",
        "\n",
        "X = vectorizer.fit_transform(train['clean_text'])\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NEGATIVE' 'NEUTRAL' 'POSITIVE']\n",
            "(283835, 1578)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exBxXoKk04MP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e699ca3d-f3f2-45d7-fe01-aef37764cff6"
      },
      "source": [
        "# over-sampling with SMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "oversample = SMOTE()\n",
        "%time X_over, y_over = oversample.fit_resample(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6min 11s, sys: 7.09 s, total: 6min 18s\n",
            "Wall time: 6min 5s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMUg-p-WIhPd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "399ba1a1-d816-4886-f5d0-0d83a4e58ea2"
      },
      "source": [
        "X_over.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(726252, 1578)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-tM4GR_bB6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the sparse matrix X_over\n",
        "from scipy import sparse\n",
        "sparse.save_npz(\"X_over.npz\", X_over)\n",
        "np.save('y_over.npy', y_over)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft8DBpjqAtWS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "4e646ad5-dfd9-4abc-d7c4-12d8d42d3c58"
      },
      "source": [
        "#fitting the model \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_over = LogisticRegression(n_jobs=-1, class_weight='balanced')\n",
        "%time logistic_over.fit(X_over, y_over)\n",
        "print(logistic_over)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 58.2 ms, sys: 206 ms, total: 264 ms\n",
            "Wall time: 32.6 s\n",
            "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=-1, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV2exfR09Sk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_X = vectorizer.transform(test['clean_text']) # transform text into word counts\n",
        "new_y = labels2numbers.transform(test['sentiment']) # transform labels into numbers\n",
        "new_predictions = logistic_over.predict(new_X) # prediction using the logistic classifier "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WguCzj1q04FH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "f6064815-fd52-40e8-c7ab-bce5938cc4b3"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(new_y, new_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.13      0.64      0.22      5224\n",
            "           1       0.94      0.68      0.78    119205\n",
            "           2       0.36      0.67      0.47     15371\n",
            "\n",
            "    accuracy                           0.67    139800\n",
            "   macro avg       0.48      0.66      0.49    139800\n",
            "weighted avg       0.84      0.67      0.73    139800\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAdCepTWSRl_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "236e72d4-df00-4da9-ebae-94b08b401cbf"
      },
      "source": [
        "# save the model \n",
        "from joblib import dump\n",
        "dump(logistic_over, 'tweet_data/models/logistic_over.joblib') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tweet_data/models/logistic_over.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q454quVZQm0J",
        "colab_type": "text"
      },
      "source": [
        "## Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL7N8A7BrIFI",
        "colab_type": "text"
      },
      "source": [
        "We consider only two sentiment: negative and non-negative (that includes positive and neutral tweets)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO0Hx5abHBta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"tweet_data/train.csv\", lineterminator='\\n')\n",
        "test = pd.read_csv(\"tweet_data/test.csv\", lineterminator='\\n')\n",
        "train_under  = pd.read_csv(\"tweet_data/train_under.csv\", lineterminator='\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NqghQo-QqPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the new train and test files are obtained from the original (unbalanced) version of the sport dataset\n",
        "train_dual = train[train['sentiment'] != 'NEUTRAL']\n",
        "test_dual = test[test['sentiment'] != 'NEUTRAL']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIGDebzAi1e5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "57ee6033-433e-46c9-b284-c978b97817b2"
      },
      "source": [
        "sentiment_label = train_dual.sentiment.factorize()\n",
        "sentiment_label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 0, ..., 0, 0, 1]),\n",
              " Index(['POSITIVE', 'NEGATIVE'], dtype='object'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7c2SkuMPb_B",
        "colab_type": "text"
      },
      "source": [
        "### LSTM - Binary "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm_eubJPhx-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tweet = train_dual.clean_text # retrive the text data \n",
        "\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(tweet)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "encoded_docs = tokenizer.texts_to_sequences(tweet)\n",
        "\n",
        "padded_sequence = pad_sequences(encoded_docs, maxlen=200) #padding "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-Hpf7SwiQLk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "c8035a98-305c-4379-8449-ca35b09546fe"
      },
      "source": [
        "# Build the model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.layers import SpatialDropout1D\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding_vector_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_vector_length, input_length=200) )\n",
        "# model.add(SpatialDropout1D(0.25))\n",
        "model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 200, 32)           939168    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 200, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50)                16600     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 955,819\n",
            "Trainable params: 955,819\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKCd2dpKihTY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "75d5fbe2-885d-45ad-9cb6-85afbe73692c"
      },
      "source": [
        "history = model.fit(padded_sequence,sentiment_label[0],\n",
        "                  validation_split=0.2, epochs=5, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1044/1044 [==============================] - 265s 254ms/step - loss: 0.3302 - accuracy: 0.8569 - val_loss: 0.2440 - val_accuracy: 0.8999\n",
            "Epoch 2/5\n",
            "1044/1044 [==============================] - 268s 257ms/step - loss: 0.2103 - accuracy: 0.9178 - val_loss: 0.2358 - val_accuracy: 0.9062\n",
            "Epoch 3/5\n",
            "1044/1044 [==============================] - 266s 255ms/step - loss: 0.1834 - accuracy: 0.9302 - val_loss: 0.2365 - val_accuracy: 0.9080\n",
            "Epoch 4/5\n",
            "1044/1044 [==============================] - 264s 253ms/step - loss: 0.1626 - accuracy: 0.9380 - val_loss: 0.2466 - val_accuracy: 0.9049\n",
            "Epoch 5/5\n",
            "1044/1044 [==============================] - 269s 258ms/step - loss: 0.1485 - accuracy: 0.9449 - val_loss: 0.2560 - val_accuracy: 0.9055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPhG7G9-uKd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('lstm.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViJzjufmHTIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the lstm model if already trained \n",
        "import tensorflow as tf \n",
        "model = tf.keras.models.load_model('lstm.h5')\n",
        "# from keras.models import load_model\n",
        "# model = load_model('lstm.h5') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BEOwd_emDc4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f351c9f2-88f4-4558-8625-b6008d63485f"
      },
      "source": [
        "# plot train and validation loss\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model train vs validation loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lom2vymXjn9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tw = tokenizer.texts_to_sequences(test_dual.clean_text)\n",
        "tw = pad_sequences(tw,maxlen=200)\n",
        "prediction = model.predict(tw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkSISOK2mC_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 0 is POSITIVE, 1 is NEGATIVE\n",
        "# we consider a score < 0.5 as POSITIVE and a score > 0.5 as NEGATIVE\n",
        "sentiment = []\n",
        "for pred in prediction: \n",
        "  if pred < 0.5: \n",
        "    sentiment.append('POSITIVE')\n",
        "  else: \n",
        "    sentiment.append('NEGATIVE')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYW_22aJxCG9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "d8b2d225-1f50-4ac5-c2b8-fd1eb67b62e5"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_dual['sentiment'], sentiment))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.82      0.80      0.81      5224\n",
            "    POSITIVE       0.93      0.94      0.94     15371\n",
            "\n",
            "    accuracy                           0.90     20595\n",
            "   macro avg       0.88      0.87      0.87     20595\n",
            "weighted avg       0.90      0.90      0.90     20595\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAp1G3alpkXt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae1e9408-1bb1-43fb-a3b9-7be200e6bc28"
      },
      "source": [
        "print(sentiment[0], test_dual['tweet_text'][15])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NEGATIVE Tanti auguri @G_Higuain sar ma cmq a me manchi...E mi dispiace vederti li ?auguri #pipita\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg9uVsM_S9Cn",
        "colab_type": "text"
      },
      "source": [
        "### LSTM - Categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RO8olsQJA9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"tweet_data/train.csv\", lineterminator='\\n')\n",
        "test = pd.read_csv(\"tweet_data/test.csv\", lineterminator='\\n')\n",
        "train_under = pd.read_csv(\"tweet_data/train_under.csv\", lineterminator='\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAeTRLc9TVRk",
        "colab_type": "text"
      },
      "source": [
        "#### Under-sampling dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID2sSf8oTAA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import keras\n",
        "\n",
        "train_texts = train_under['clean_text']\n",
        "test_texts = test['clean_text']\n",
        "\n",
        "# tokenizer \n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(train_texts)\n",
        "X_train = t.texts_to_sequences(train_texts)\n",
        "\n",
        "# transform labels into numbers\n",
        "labels2numbers = LabelEncoder()\n",
        "y_train_org = labels2numbers.fit_transform(train_under['sentiment'])\n",
        "\n",
        "\n",
        "X_test = t.texts_to_sequences(test_texts)\n",
        "y_test_org = labels2numbers.transform(test['sentiment'])\n",
        "\n",
        "num_classes = max(y_train_org) + 1 # get number of classes for transformation\n",
        "vocab_size = len(t.word_index) + 1 # vocabulary size (plus reserved index 0)\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train_org, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test_org, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwXI2WiSTiy7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "8fa76732-2cbe-404c-85ea-10a6e3f18ff7"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional, LSTM, CuDNNLSTM, Embedding, Flatten\n",
        "from keras.layers.core import Lambda, Dropout, Dense, Activation\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras import backend as K\n",
        "\n",
        "hidden_dims = 96\n",
        "lstm_dims = 48\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(output_dim=64, \n",
        "                    input_dim=vocab_size,\n",
        "                    input_length=None))\n",
        "model.add(LSTM(lstm_dims))\n",
        "model.add(Dense(hidden_dims))\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 64)          1844928   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 48)                21696     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 96)                4704      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 96)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 96)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 291       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 1,871,619\n",
            "Trainable params: 1,871,619\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7pMUzFrTupe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# padding \n",
        "k = sorted([len(xx) for xx in X_train])\n",
        "f = k[int(len(k)/100*90)]\n",
        "\n",
        "maxlen = f\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeuXTiZDTw9q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "b93ba1b6-0591-43ed-8862-57de46d1909d"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 5\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.2)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test,\n",
        "                       batch_size=batch_size, verbose=1)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25816 samples, validate on 6455 samples\n",
            "Epoch 1/5\n",
            "25816/25816 [==============================] - 27s 1ms/step - loss: 0.7317 - accuracy: 0.6850 - val_loss: 1.0292 - val_accuracy: 0.5701\n",
            "Epoch 2/5\n",
            "25816/25816 [==============================] - 27s 1ms/step - loss: 0.4685 - accuracy: 0.8214 - val_loss: 0.9965 - val_accuracy: 0.6183\n",
            "Epoch 3/5\n",
            "25816/25816 [==============================] - 27s 1ms/step - loss: 0.3383 - accuracy: 0.8748 - val_loss: 1.2906 - val_accuracy: 0.5875\n",
            "Epoch 4/5\n",
            "25816/25816 [==============================] - 27s 1ms/step - loss: 0.2568 - accuracy: 0.9093 - val_loss: 1.2512 - val_accuracy: 0.6229\n",
            "Epoch 5/5\n",
            "25816/25816 [==============================] - 27s 1ms/step - loss: 0.1996 - accuracy: 0.9275 - val_loss: 1.9544 - val_accuracy: 0.5771\n",
            "139800/139800 [==============================] - 12s 87us/step\n",
            "Test loss: 1.1742022013425486\n",
            "Test accuracy: 0.6444063186645508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfo22IV4bRuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('lstm_category_under.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy2weuOlT8gE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict(X_test)\n",
        "sentiment = []\n",
        "for pred in prediction: \n",
        "  sentiment.append(labels2numbers.inverse_transform([pred.argmax()])[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SwBNoH-UINP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "ac3ece80-49a2-4aae-f120-0bb0aa247eb4"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test['sentiment'], sentiment))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.43      0.33      0.37      5224\n",
            "     NEUTRAL       0.91      0.94      0.92    119205\n",
            "    POSITIVE       0.58      0.45      0.50     15371\n",
            "\n",
            "    accuracy                           0.87    139800\n",
            "   macro avg       0.64      0.57      0.60    139800\n",
            "weighted avg       0.85      0.87      0.86    139800\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk-5uokYuKBi",
        "colab_type": "text"
      },
      "source": [
        "#### Over-sampling dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQSxKS7huQ6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import keras\n",
        "\n",
        "train_texts = train['clean_text']\n",
        "test_texts = test['clean_text']\n",
        "\n",
        "# tokenizer \n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(train_texts)\n",
        "X_train = t.texts_to_sequences(train_texts)\n",
        "\n",
        "# transform labels into numbers\n",
        "labels2numbers = LabelEncoder()\n",
        "y_train_org = labels2numbers.fit_transform(train['sentiment'])\n",
        "\n",
        "X_test = t.texts_to_sequences(test_texts)\n",
        "y_test_org = labels2numbers.transform(test['sentiment'])\n",
        "\n",
        "num_classes = max(y_train_org) + 1 # get number of classes for transformation\n",
        "vocab_size = len(t.word_index) + 1 # vocabulary size (plus reserved index 0)\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train_org, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test_org, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BEHtMChuuc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# padding \n",
        "k = sorted([len(xx) for xx in X_train])\n",
        "f = k[int(len(k)/100*90)]\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "maxlen = f\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p85sKxTTuMkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1628a75a-c192-427d-dfb6-c7fc644d2851"
      },
      "source": [
        "# over-sampling with SMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "oversample = SMOTE()\n",
        "%time X_over, y_over = oversample.fit_resample(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 16.8 s, sys: 402 s, total: 16.8 s\n",
            "Wall time: 16.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u-KoiK0u75u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "7bed1321-412a-4215-b217-b7ec224409e3"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional, LSTM, CuDNNLSTM, Embedding, Flatten\n",
        "from keras.layers.core import Lambda, Dropout, Dense, Activation\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras import backend as K\n",
        "\n",
        "hidden_dims = 96\n",
        "lstm_dims = 48\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(output_dim=64, \n",
        "                    input_dim=vocab_size,\n",
        "                    input_length=None))\n",
        "model.add(LSTM(lstm_dims))\n",
        "model.add(Dense(hidden_dims))\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, None, 64)          6420480   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 48)                21696     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 96)                4704      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 96)                0         \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 96)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 3)                 291       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 6,447,171\n",
            "Trainable params: 6,447,171\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh3w0igGvBLe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "7d954a62-3b8c-495c-ad1c-dedec69d1f2c"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 5\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.2)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test,\n",
        "                       batch_size=batch_size, verbose=1)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 227068 samples, validate on 56767 samples\n",
            "Epoch 1/5\n",
            "227068/227068 [==============================] - 607s 3ms/step - loss: 0.3605 - accuracy: 0.8748 - val_loss: 0.3339 - val_accuracy: 0.8801\n",
            "Epoch 2/5\n",
            "227068/227068 [==============================] - 602s 3ms/step - loss: 0.2933 - accuracy: 0.8904 - val_loss: 0.3302 - val_accuracy: 0.8805\n",
            "Epoch 3/5\n",
            "227068/227068 [==============================] - 597s 3ms/step - loss: 0.2470 - accuracy: 0.9067 - val_loss: 0.3621 - val_accuracy: 0.8736\n",
            "Epoch 4/5\n",
            "227068/227068 [==============================] - 596s 3ms/step - loss: 0.2057 - accuracy: 0.9232 - val_loss: 0.4206 - val_accuracy: 0.8649\n",
            "Epoch 5/5\n",
            "227068/227068 [==============================] - 594s 3ms/step - loss: 0.1720 - accuracy: 0.9362 - val_loss: 0.4949 - val_accuracy: 0.8523\n",
            "139800/139800 [==============================] - 11s 78us/step\n",
            "Test loss: 0.468470223671377\n",
            "Test accuracy: 0.8626537919044495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e4PGxF8pvOMO",
        "colab": {}
      },
      "source": [
        "model.save('lstm_category_over.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uGNQ34xuvOMS",
        "colab": {}
      },
      "source": [
        "prediction = model.predict(X_test)\n",
        "sentiment = []\n",
        "for pred in prediction: \n",
        "  sentiment.append(labels2numbers.inverse_transform([pred.argmax()])[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vR1kKEqNvOMU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "9fda7011-4376-4902-f788-f3f2292dc0a3"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test['sentiment'], sentiment))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.43      0.34      0.38      5224\n",
            "     NEUTRAL       0.91      0.93      0.92    119205\n",
            "    POSITIVE       0.56      0.49      0.52     15371\n",
            "\n",
            "    accuracy                           0.86    139800\n",
            "   macro avg       0.63      0.59      0.61    139800\n",
            "weighted avg       0.85      0.86      0.86    139800\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phkPXWDXTkje",
        "colab_type": "text"
      },
      "source": [
        "#### Original (unbalanced) dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTF0NXQETo88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import keras\n",
        "\n",
        "train_texts = train['clean_text']\n",
        "test_texts = test['clean_text']\n",
        "\n",
        "# tokenizer \n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(train_texts)\n",
        "X_train = t.texts_to_sequences(train_texts)\n",
        "\n",
        "# transform labels into numbers\n",
        "labels2numbers = LabelEncoder()\n",
        "y_train_org = labels2numbers.fit_transform(train['sentiment'])\n",
        "\n",
        "\n",
        "X_test = t.texts_to_sequences(test_texts)\n",
        "y_test_org = labels2numbers.transform(test['sentiment'])\n",
        "\n",
        "num_classes = max(y_train_org) + 1 # get number of classes for transformation\n",
        "vocab_size = len(t.word_index) + 1 # vocabulary size (plus reserved index 0)\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train_org, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test_org, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEC59WHGTzgs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "6325f19e-946e-4a47-bbeb-2138ec686d22"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional, LSTM, CuDNNLSTM, Embedding, Flatten\n",
        "from keras.layers.core import Lambda, Dropout, Dense, Activation\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras import backend as K\n",
        "\n",
        "hidden_dims = 96\n",
        "lstm_dims = 48\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(output_dim=64, \n",
        "                    input_dim=vocab_size,\n",
        "                    input_length=None))\n",
        "model.add(LSTM(lstm_dims))\n",
        "model.add(Dense(hidden_dims))\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 64)          6420480   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 48)                21696     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 96)                4704      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 96)                0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 96)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 291       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 6,447,171\n",
            "Trainable params: 6,447,171\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPtLshEIT0YI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# padding \n",
        "k = sorted([len(xx) for xx in X_train])\n",
        "f = k[int(len(k)/100*90)]\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "maxlen = f\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWxqhhIET-Zw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "46f3a63c-fba8-4a27-c508-c45d19b005b1"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 5\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.2)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test,\n",
        "                       batch_size=batch_size, verbose=1)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 227068 samples, validate on 56767 samples\n",
            "Epoch 1/5\n",
            "227068/227068 [==============================] - 611s 3ms/step - loss: 0.3608 - accuracy: 0.8753 - val_loss: 0.3314 - val_accuracy: 0.8797\n",
            "Epoch 2/5\n",
            "227068/227068 [==============================] - 605s 3ms/step - loss: 0.2927 - accuracy: 0.8908 - val_loss: 0.3352 - val_accuracy: 0.8797\n",
            "Epoch 3/5\n",
            "227068/227068 [==============================] - 595s 3ms/step - loss: 0.2452 - accuracy: 0.9077 - val_loss: 0.3723 - val_accuracy: 0.8726\n",
            "Epoch 4/5\n",
            "227068/227068 [==============================] - 601s 3ms/step - loss: 0.2047 - accuracy: 0.9234 - val_loss: 0.4120 - val_accuracy: 0.8570\n",
            "Epoch 5/5\n",
            "227068/227068 [==============================] - 602s 3ms/step - loss: 0.1718 - accuracy: 0.9360 - val_loss: 0.4672 - val_accuracy: 0.8544\n",
            "139800/139800 [==============================] - 11s 81us/step\n",
            "Test loss: 0.4464702679867055\n",
            "Test accuracy: 0.8644635081291199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPBw_CIfUDmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('lstm_category.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PixJkfKUHwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict(X_test)\n",
        "sentiment = []\n",
        "for pred in prediction: \n",
        "  sentiment.append(labels2numbers.inverse_transform([pred.argmax()])[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YHHQsBiUJUy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "f8191386-f1da-4812-f1e8-c158dd23e542"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test['sentiment'], sentiment))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.48      0.31      0.38      5224\n",
            "     NEUTRAL       0.91      0.93      0.92    119205\n",
            "    POSITIVE       0.55      0.51      0.53     15371\n",
            "\n",
            "    accuracy                           0.86    139800\n",
            "   macro avg       0.65      0.58      0.61    139800\n",
            "weighted avg       0.86      0.86      0.86    139800\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvGksNU1IOs8",
        "colab_type": "text"
      },
      "source": [
        "# Predictions on covid tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlOE7jADB_jq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_week = pd.read_csv(\"tweet_data/first_week.csv\")\n",
        "second_week = pd.read_csv(\"tweet_data/second_week.csv\")\n",
        "third_week = pd.read_csv(\"tweet_data/third_week.csv\")\n",
        "fourth_week = pd.read_csv(\"tweet_data/fourth_week.csv\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNzU56v2DjW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_week = first_week[first_week.clean_text.isna()==False] # drop all tweets without text\n",
        "second_week = second_week[second_week.clean_text.isna()==False] # drop all tweets without text\n",
        "third_week = third_week[third_week.clean_text.isna()==False] # drop all tweets without text\n",
        "fourth_week = fourth_week[fourth_week.clean_text.isna()==False] # drop all tweets without text"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaHgCLHLePmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_under = pd.read_csv(\"tweet_data/train_under.csv\")\n",
        "train = pd.read_csv(\"tweet_data/train.csv\", lineterminator='\\n')\n",
        "test = pd.read_csv(\"tweet_data/test.csv\", lineterminator='\\n')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWteJyjjFd9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "def print_tweet(dataset, emotion, model, number = 5): \n",
        "  df = dataset.loc[dataset[model] == emotion]\n",
        "  random_idx = random.sample(list(df.index), number)\n",
        "  tweet = [] \n",
        "  for idx in random_idx: \n",
        "    tweet.append(df['text'][idx])\n",
        "  return tweet"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiGyqvqLMgQ3",
        "colab_type": "text"
      },
      "source": [
        "### Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YensQ8FTMfmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the models\n",
        "from joblib import load\n",
        "logistic_under = load('tweet_data/models/logistic_under.joblib') \n",
        "logistic_over = load('tweet_data/models/logistic_over.joblib') \n",
        "logistic_original = load('tweet_data/models/logistic_original.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY53wOxmMv_n",
        "colab_type": "text"
      },
      "source": [
        "#### Under-sampling model\n",
        "Create the same vectorizer used during the training phase with the *train_under* dataset. Then use the clean version of tweets as test to predict the sentiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkBvP2yvMycv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e819f84-dc75-4c57-b6d1-fef419d7cce3"
      },
      "source": [
        "# create the same vectorizer used during the training phase \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,4), \n",
        "                             min_df=0.001, \n",
        "                             max_df=0.75)\n",
        "\n",
        "X_under = vectorizer.fit_transform(train_under['clean_text'])\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labels2numbers = LabelEncoder()\n",
        "y_under = labels2numbers.fit_transform(train_under['sentiment'])\n",
        "print(labels2numbers.classes_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NEGATIVE' 'NEUTRAL' 'POSITIVE']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e9K-tS4M-Wh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "adca0d60-44cf-4ca2-e150-bba5d4461417"
      },
      "source": [
        "# first week \n",
        "new_X = vectorizer.transform(first_week['clean_text'])\n",
        "predw1_logistic_under = logistic_under.predict(new_X)\n",
        "first_week['sentiment_log_under'] = labels2numbers.inverse_transform(predw1_logistic_under)\n",
        "first_week_counts = first_week['sentiment_log_under'].value_counts()\n",
        "\n",
        "# store result in a pretty table \n",
        "from prettytable import PrettyTable\n",
        "w1_logistic = PrettyTable(['Model', 'Positive' ,'Negative', 'Neutral'])\n",
        "w1_logistic.add_row(['Logistic Regression (under)', \n",
        "           round((first_week_counts[2]/first_week.shape[0] * 100),2), \n",
        "           round((first_week_counts[1]/first_week.shape[0] * 100),2), \n",
        "           round((first_week_counts[0]/first_week.shape[0] * 100),2) ])\n",
        "print(w1_logistic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------+----------+----------+---------+\n",
            "|            Model            | Positive | Negative | Neutral |\n",
            "+-----------------------------+----------+----------+---------+\n",
            "| Logistic Regression (under) |   8.13   |  16.38   |  75.49  |\n",
            "+-----------------------------+----------+----------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4kLoP4eNfy-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "5666edee-69c6-4c4b-967b-4fe9379e1d17"
      },
      "source": [
        "# second week \n",
        "new_X = vectorizer.transform(second_week['clean_text'])\n",
        "predw2_logistic_under = logistic_under.predict(new_X)\n",
        "second_week['sentiment_log_under'] = labels2numbers.inverse_transform(predw2_logistic_under)\n",
        "second_week_counts = second_week['sentiment_log_under'].value_counts()\n",
        "w2_logistic = PrettyTable(['Model', 'Positive' ,'Negative', 'Neutral'])\n",
        "w2_logistic.add_row(['Logistic Regression (under)', \n",
        "           round((second_week_counts[2]/second_week.shape[0] * 100),2), \n",
        "           round((second_week_counts[1]/second_week.shape[0] * 100),2), \n",
        "           round((second_week_counts[0]/second_week.shape[0] * 100),2) ])\n",
        "print(w2_logistic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------+----------+----------+---------+\n",
            "|            Model            | Positive | Negative | Neutral |\n",
            "+-----------------------------+----------+----------+---------+\n",
            "| Logistic Regression (under) |   12.5   |  14.69   |   72.8  |\n",
            "+-----------------------------+----------+----------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3xTnqEhODll",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "3859d253-aace-4942-8823-f50e1a972189"
      },
      "source": [
        "# third week \n",
        "new_X = vectorizer.transform(third_week['clean_text'])\n",
        "predw3_logistic_under = logistic_under.predict(new_X)\n",
        "third_week['sentiment_log_under'] = labels2numbers.inverse_transform(predw3_logistic_under)\n",
        "third_week_counts = third_week['sentiment_log_under'].value_counts()\n",
        "w3_logistic = PrettyTable(['Model', 'Positive' ,'Negative', 'Neutral'])\n",
        "w3_logistic.add_row(['Logistic Regression (under)', \n",
        "           round((third_week_counts[2]/third_week.shape[0] * 100),2), \n",
        "           round((third_week_counts[1]/third_week.shape[0] * 100),2), \n",
        "           round((third_week_counts[0]/third_week.shape[0] * 100),2) ])\n",
        "print(w3_logistic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------+----------+----------+---------+\n",
            "|            Model            | Positive | Negative | Neutral |\n",
            "+-----------------------------+----------+----------+---------+\n",
            "| Logistic Regression (under) |   11.5   |  13.94   |  74.57  |\n",
            "+-----------------------------+----------+----------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKx5bzC4OR_9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "bc5a5f72-d8a4-4018-adfc-ac553382a966"
      },
      "source": [
        "new_X = vectorizer.transform(fourth_week['clean_text'])\n",
        "predw4_logistic_under = logistic_under.predict(new_X)\n",
        "fourth_week['sentiment_log_under'] = labels2numbers.inverse_transform(predw4_logistic_under)\n",
        "fourth_week_counts = fourth_week['sentiment_log_under'].value_counts()\n",
        "w4_logistic = PrettyTable(['Model', 'Positive' ,'Negative', 'Neutral'])\n",
        "w4_logistic.add_row(['Logistic Regression (under)', \n",
        "           round((fourth_week_counts[2]/fourth_week.shape[0] * 100),2), \n",
        "           round((fourth_week_counts[1]/fourth_week.shape[0] * 100),2), \n",
        "           round((fourth_week_counts[0]/fourth_week.shape[0] * 100),2) ])\n",
        "print(w4_logistic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------+----------+----------+---------+\n",
            "|            Model            | Positive | Negative | Neutral |\n",
            "+-----------------------------+----------+----------+---------+\n",
            "| Logistic Regression (under) |   9.89   |   14.0   |  76.11  |\n",
            "+-----------------------------+----------+----------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie0THUtXO_cw",
        "colab_type": "text"
      },
      "source": [
        "#### Over-sampling model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAMlbJr-PS7N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d9998e5-4905-41f1-a656-1f54430f5853"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,4), \n",
        "                             min_df=0.001, \n",
        "                             max_df=0.75)\n",
        "\n",
        "X = vectorizer.fit_transform(train['clean_text'])\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labels2numbers = LabelEncoder()\n",
        "y = labels2numbers.fit_transform(train['sentiment'])\n",
        "print(labels2numbers.classes_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NEGATIVE' 'NEUTRAL' 'POSITIVE']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMsincX7PM8D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "784ad6e3-529c-4d75-ec75-8f1f72e27456"
      },
      "source": [
        "# first week \n",
        "new_X = vectorizer.transform(first_week['clean_text'])\n",
        "predw1_logistic_over = logistic_over.predict(new_X)\n",
        "first_week['sentiment_log_over'] = labels2numbers.inverse_transform(predw1_logistic_over)\n",
        "first_week_counts = first_week['sentiment_log_over'].value_counts()\n",
        "\n",
        "w1_logistic.add_row(['Logistic Regression (over)', \n",
        "           round((first_week_counts[2]/first_week.shape[0] * 100),2), \n",
        "           round((first_week_counts[1]/first_week.shape[0] * 100),2), \n",
        "           round((first_week_counts[0]/first_week.shape[0] * 100),2) ])\n",
        "print(w1_logistic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------+----------+----------+---------+\n",
            "|            Model            | Positive | Negative | Neutral |\n",
            "+-----------------------------+----------+----------+---------+\n",
            "| Logistic Regression (under) |   8.13   |  16.38   |  75.49  |\n",
            "|  Logistic Regression (over) |  11.74   |  36.56   |   51.7  |\n",
            "+-----------------------------+----------+----------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN6iwlgxPM47",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "ead0adc1-634a-4241-febc-e43dbd3e1558"
      },
      "source": [
        "# second week \n",
        "new_X = vectorizer.transform(second_week['clean_text'])\n",
        "predw2_logistic_over = logistic_over.predict(new_X)\n",
        "second_week['sentiment_log_over'] = labels2numbers.inverse_transform(predw2_logistic_over)\n",
        "second_week_counts = second_week['sentiment_log_over'].value_counts()\n",
        "w2_logistic.add_row(['Logistic Regression (over)', \n",
        "           round((second_week_counts[2]/second_week.shape[0] * 100),2), \n",
        "           round((second_week_counts[1]/second_week.shape[0] * 100),2), \n",
        "           round((second_week_counts[0]/second_week.shape[0] * 100),2) ])\n",
        "print(w2_logistic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------+----------+----------+---------+\n",
            "|            Model            | Positive | Negative | Neutral |\n",
            "+-----------------------------+----------+----------+---------+\n",
            "| Logistic Regression (under) |   12.5   |  14.69   |   72.8  |\n",
            "|  Logistic Regression (over) |  16.12   |  31.15   |  52.73  |\n",
            "+-----------------------------+----------+----------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw0gqQ6APM1O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "ae1ea7ca-2a26-4972-caae-ce3635086fb5"
      },
      "source": [
        "# third week \n",
        "new_X = vectorizer.transform(third_week['clean_text'])\n",
        "predw3_logistic_over = logistic_over.predict(new_X)\n",
        "third_week['sentiment_log_over'] = labels2numbers.inverse_transform(predw3_logistic_over)\n",
        "third_week_counts = third_week['sentiment_log_over'].value_counts()\n",
        "w3_logistic.add_row(['Logistic Regression (over)', \n",
        "           round((third_week_counts[2]/third_week.shape[0] * 100),2), \n",
        "           round((third_week_counts[1]/third_week.shape[0] * 100),2), \n",
        "           round((third_week_counts[0]/third_week.shape[0] * 100),2) ])\n",
        "print(w3_logistic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------+----------+----------+---------+\n",
            "|            Model            | Positive | Negative | Neutral |\n",
            "+-----------------------------+----------+----------+---------+\n",
            "| Logistic Regression (under) |   11.5   |  13.94   |  74.57  |\n",
            "|  Logistic Regression (over) |  14.57   |  32.61   |  52.82  |\n",
            "+-----------------------------+----------+----------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjRVAHwDPggg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "cb6cd994-8045-48fe-a45b-bba9e4b80397"
      },
      "source": [
        "# fourth week \n",
        "new_X = vectorizer.transform(fourth_week['clean_text'])\n",
        "predw4_logistic_over = logistic_over.predict(new_X)\n",
        "fourth_week['sentiment_log_over'] = labels2numbers.inverse_transform(predw4_logistic_over)\n",
        "fourth_week_counts = fourth_week['sentiment_log_over'].value_counts()\n",
        "w4_logistic.add_row(['Logistic Regression (over)', \n",
        "           round((fourth_week_counts[2]/fourth_week.shape[0] * 100),2), \n",
        "           round((fourth_week_counts[1]/fourth_week.shape[0] * 100),2), \n",
        "           round((fourth_week_counts[0]/fourth_week.shape[0] * 100),2) ])\n",
        "print(w4_logistic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------+----------+----------+---------+\n",
            "|            Model            | Positive | Negative | Neutral |\n",
            "+-----------------------------+----------+----------+---------+\n",
            "| Logistic Regression (under) |   9.89   |   14.0   |  76.11  |\n",
            "|  Logistic Regression (over) |  13.77   |  33.86   |  52.37  |\n",
            "+-----------------------------+----------+----------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlbfMdQcQelP",
        "colab_type": "text"
      },
      "source": [
        "#### Classification difference "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhKZfghLQk8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def different_sentiment(row): \n",
        "  difference = row['sentiment_log_over'] != row['sentiment_log_under']\n",
        "  if difference: \n",
        "    return row['sentiment_log_over'] +\"-\"+ row['sentiment_log_under']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeU6JU4bQ77x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "d670fe7d-2520-4ebc-f860-e81371f9258d"
      },
      "source": [
        "first_week['log_difference'] = first_week.apply(lambda row: different_sentiment(row), axis = 1 )\n",
        "first_week['log_difference'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NEGATIVE-NEUTRAL     44711\n",
              "POSITIVE-NEUTRAL     10934\n",
              "NEUTRAL-NEGATIVE      6856\n",
              "NEUTRAL-POSITIVE      3277\n",
              "NEGATIVE-POSITIVE     1504\n",
              "POSITIVE-NEGATIVE      751\n",
              "Name: log_difference, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1ksvTaRQkXC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "9236b3e6-b945-4fae-eb9a-8e1fd1f21671"
      },
      "source": [
        "second_week['log_difference'] = second_week.apply(lambda row: different_sentiment(row), axis = 1 )\n",
        "second_week['log_difference'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NEGATIVE-NEUTRAL     64985\n",
              "POSITIVE-NEUTRAL     22528\n",
              "NEUTRAL-NEGATIVE     12577\n",
              "NEUTRAL-POSITIVE      9471\n",
              "NEGATIVE-POSITIVE     2515\n",
              "POSITIVE-NEGATIVE     1262\n",
              "Name: log_difference, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqkwkrfjRUSp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "f0e5ac64-7003-40f0-f43e-633c7bc5fb2d"
      },
      "source": [
        "third_week['log_difference'] = third_week.apply(lambda row: different_sentiment(row), axis = 1 )\n",
        "third_week['log_difference'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NEGATIVE-NEUTRAL     37671\n",
              "POSITIVE-NEUTRAL     10853\n",
              "NEUTRAL-NEGATIVE      5722\n",
              "NEUTRAL-POSITIVE      4587\n",
              "NEGATIVE-POSITIVE     1624\n",
              "POSITIVE-NEGATIVE      754\n",
              "Name: log_difference, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CgJN9YiRVLD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "0173838e-defb-4bbe-f041-ec2a38131a74"
      },
      "source": [
        "fourth_week['log_difference'] = fourth_week.apply(lambda row: different_sentiment(row), axis = 1 )\n",
        "fourth_week['log_difference'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NEGATIVE-NEUTRAL     19980\n",
              "POSITIVE-NEUTRAL      5793\n",
              "NEUTRAL-NEGATIVE      2722\n",
              "NEUTRAL-POSITIVE      2063\n",
              "NEGATIVE-POSITIVE      654\n",
              "POSITIVE-NEGATIVE      359\n",
              "Name: log_difference, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNTQrS9tRsRh",
        "colab_type": "text"
      },
      "source": [
        "#### Print tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBG6ArkoBTAL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "0cbc03a7-5f58-4d80-da2e-3588b334225c"
      },
      "source": [
        "print_tweet(first_week, 'NEGATIVE', 'sentiment_log_under', 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Pi di 1000 positivi al #coronavirus ed  psicosi da mascherina e amuchina, nel mondo 30 milioni di persone con l'#AIDS e ancora non usiamo il preservativo, per non dimentare 8 bambini morti in 20gg a #Taranto e anche l il nulla \",\n",
              " 'Quando usate un hashtag io lo capisco se  un hashtag coerente, se di cortesia (per permettere il mute a chi non frega un cazzo dellargomento) o se lo mettete solo per guadagnare qualche visualizzazione. PEZZENTI! \\n#COVID19 #coronarvirusitalia #TetteGrandi #ScopareGratis #Figa',\n",
              " 'Per il #coronavirus, come al solito si da la colpa al governo. Onestamente, il 2001 per accontentare la #lega, si  riformata la Costituzione e la sanit  esclusiva delle regioni. Bisognerebbe annullare quella riforma INDECENTE e ridare la sanit allo #Stato. #NonelArena',\n",
              " \"#Conte dovrebbe prendere esempio da #Fontana che, con gran senso di responsabilit, ha messo a tacere le polemiche, dimostrandosi grande rappresentante delle istituzioni, concentrandosi solo sulla gestione dell'emergenza: avanti! #coronavirus #Lombardia https://t.co/KCOVQ6ppJx https://t.co/XCHhSbq6vd\",\n",
              " 'Di vecchiaia si vive. Dolorosa riflessione di Adriano Sofri, per chi si sente rassicurato se di #coronavirus muoiono solo i vecchi gi malati https://t.co/AOXkKuvYuD',\n",
              " 'Stupido autogol comunicativo delle istituzioni e di noi cittadini italiani. Adesso sta a noi a invertire il messaggio a ns favore, senza piangerci addosso!!! #coronavirus #COVID19 #Italia https://t.co/1TRAaICqzf',\n",
              " \"#valledelsacco Mi preoccupa di pi la possibilit di morire di #tumore a causa dell'aria merdosa che respiro ogni giorno, che la possibilit di contrarre il #coronavirus.\",\n",
              " \"#Coronavirus, crolla l'#economia. Aziende nel panico: Solo 10%  assicurata - https://t.co/oEFAxjDwPu https://t.co/pgN8IPnfRp\",\n",
              " 'Ci sar da rimboccarsi le maniche e immettere liquidit per sostenere questo dramma #economico..\\n\\nSentiremo tanti \"facciamo deficit\" e pochi \"tagliamoci lo stipendio\" \\n\\nEppure il @Mov5Stelle cerca di metterlo a norma invano da parecchi anni\\n\\nChe fosse la volta buona?\\n#coronavirus',\n",
              " 'Capuozzo sferza Mattarella: \"Sul coronavirus ha sbagliato\" https://t.co/Jw5kO9poEo']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idl-98jukeSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "a0d8eea2-4fcc-4f44-a045-60deda04b922"
      },
      "source": [
        "print_tweet(first_week, 'NEUTRAL', 'sentiment_log_under', 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['#Trenitalia rimborsa chi rinuncia a viaggiare. #coronavirus\\n\\nhttps://t.co/PtCOePV530',\n",
              " 'Coronavirus, Israele blocca lingresso a chi arriva dallItalia. Macron: Non chiudo le frontiere. Di Maio: Siamo un Paese affidabile  - La Stampa https://t.co/1er7xD8Jz4',\n",
              " 'Coronavirus, guanti e mascherine ai postini del Gruppo Mail Express \\xa0 https://t.co/l2oM0ZjQRH',\n",
              " 'Thread by @michelaz988: Due parole sulla narrazione grafica del #COVID19. C un divario fra il rischio e la percezione del rischio che neliminare del tutto. Compito di chi comunica, sia con i grafici che con le notizie,  far s che questo divario s https://t.co/EMOkXgGMTk',\n",
              " 'Nei Grigioni i contagiati sono due bambini\\ncoronavirus\\n\\nSono figli di una famiglia italiana in vacanza in Engadina - Annullata la Maratona Engadinese di sci di fondo https://t.co/Z7KX82Ir8A',\n",
              " 'Confermata per una settimana la chiusura di scuole, asili e universit in Lombardia, Veneto e Emilia Romagna #coronavirus',\n",
              " 'Da troppo tempo ormai seguo come tutti le informazioni che arrivano da ogni canale di informazione su cosa sta succedendo con il #coronavirus Ci sono ancora altri #rimedifloreali come ad esempio la #floriiterapia Californiana e quella Australiana. #benessere #Salute #Milano https://t.co/sX5KtPOjTU',\n",
              " 'Coronavirus: sindaco Sesto S.Giovanni misure drastiche a tutela salute pubblica -  #Coronavirus: #sindaco #Sesto  https://t.co/U9s7tiXvs2',\n",
              " \"Ad oggi la Lazio che ha giocato a porte aperte con i Bolognesi(che han le scuole e universit chiuse fino al 7 marzo per i 189 casi di coronavirus)  a +8 sull'Inter e +2 sulla Juve, ma il problema  Agnelli che vuole penalizzare i nerazzurri. Li stimo.\",\n",
              " 'Coronavirus news, chiusi tutti gli Atenei in Emilia Romagna. A rischio le scuole - Cronaca https://t.co/vSgAu5j36M']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAeAAlcokeQK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "22f17413-2c3f-44cd-f8d5-b43fc471c7d7"
      },
      "source": [
        "print_tweet(first_week, 'POSITIVE', 'sentiment_log_under', 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ringrazio di cuore @zaiapresidente per come sta gestendo la faccenda #coronavirus qui in #Veneto. Sono nata in Toscana ma per nulla al mondo cambierei il mio governatore. Mai. E sinceramente lo vedrei proprio bene come Presidente del Consiglio. Magari. #forzaZaia',\n",
              " 'Siamo felici a prenderci cura dei nostri ospiti #coronavirus #agriturismovillabracali #agriturismoserravalle #agriturismotoscano @ Agriturismo Villa Bracali https://t.co/gLOsDyfwgS',\n",
              " 'Coronavirus, il vescovo Forte: No al segno di pace e svuotate le acquasantiere https://t.co/o4tjN4xuJX #Lanciano',\n",
              " \"C' il coronavirus, la peste, moriremo tutti ma le cavallette giganti quelle no, sopravvivono a tutto belle beate e mi fanno venire un infarto volando.\\nZoccole.\",\n",
              " 'Coronavirus - Una famiglia di Ponsacco (Pisa) in quarantena: \"E\\' solo a scopo precauzionale\".\\nIl sindaco Francesca Brogi ha firmato la sera di marted l\\'apposita ordinanza. \\nLe persone sono state in contatto con un ammalato.\\nhttps://t.co/4PMb5rwOMe',\n",
              " 'Subito misure straordinarie per il rilancio dei settori compiti dalla crisi!  #CGIA #CORONAVIRUS: META DELLECONOMIA NAZIONALE E DEL GETTITO FISCALE E PRODOTTA AL #NORD! https://t.co/F35k5NiywR',\n",
              " 'Buongiorno amici, mi pare di poter lucidamente sostenere che il vero pericolo di diffusione del Coronavirus (che sia pericoloso o meno non spetta a noi giudici di Facebook ma ai virologhi) sia costituito da coloro https://t.co/qGGoSLISsm',\n",
              " 'CORONAVIRUS MESSE SOSPESE- Il suono di una campana e la nostalgia punge il cuore -  #CORONAVIRUS #MESSE #SOSPESE- #suono  https://t.co/ritWNw51JH',\n",
              " \"S' decisa la quarantena breve perch l'economia e perch uff, sar sicuramente stato informato anche il virus\",\n",
              " 'Oltre al 71enne di Cattolica sono risultati positivi un operatore dell\\'ospedale \"Cervesi\" di Cattolica e un cliente del ristorante.\\n\\n#coronavirus, la Regione annuncia due nuovi casi a Rimini https://t.co/0BvbhILOTl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6TMKsH_-ZNn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "9e282f27-a1bd-42ab-cfd9-3abd9e7b16f8"
      },
      "source": [
        "print_tweet(second_week, 'NEGATIVE', 'sentiment_log_under', 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Litaliano medio non sa vivere senza aperitivo e sente il bisogno di dire a tutti che lo fa anche in quarantena, ma in pigiama.',\n",
              " 'Ho tantissimo bisogno di uscire e farmi i cazzi miei ma non posso e non solo per la quasi-quarantena, sar cos anche quando tutta questa storia sar finita e io penso di impazzire',\n",
              " 'Ammetto che su questa cosa sono puramente ignorante, ma fortemente dubbioso.\\nLe mosche e le zanzare possono trasmettere il #coronavirus ?',\n",
              " 'Ma porca puttana madre che cazzo entri come una furia in camera mia durante la lezione MA CAZZO di grazia che ho chiuso il microfono in due secondi e che stava urlando come una dannata. Sta quarantena le fa male.',\n",
              " 'Coronavirus: studio sui primi malati italiani mostra i gravi danni ai polmoni https://t.co/hMkTZR6Y8y',\n",
              " 'Comunque in quarantena non sto mangiando molto pi del solito il problema  che sono passata da fare 15.000 passi al giorno a farne 30/35.',\n",
              " 'Sul Coronavirus la nuova offensiva della Cina per legemonia in Italia - La Stampa - Alloffensiva diplomatica corrisponde quella nella propaganda di Pechino sul web italiano. E Grillo celebra sul blog la collaborazione di Huawei https://t.co/G79xeQ0Lej di @LaStampa',\n",
              " 'voi continuate a credere alla propaganda cinese, un fottuto regime autoritario comunista... ma davvero credete anche lontanamente che i dati da loro diffusi sono lontanamente reali? AHAH!\\n\\n#coronavirus',\n",
              " '@chetempochefa Vi suete accirti che covid 19 non  solo un problema della lombardia?\\nHa colpito tutta Italia, quindi anche il centro e il sud!!!',\n",
              " 'Ma quanto siete miseri a lamentarvi del fatto che dovreste pagare di meno se i servizi di streaming diminuiscono la qualit? Togliete il servizio se non  necessario per voi. Non  una situazione ordinaria #iorestoacasa']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-dmW--Qli9a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "972a9b6d-b051-403a-8988-086541260a1a"
      },
      "source": [
        "print_tweet(second_week, 'POSITIVE', 'sentiment_log_under', 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dopo 30 giorni di ricovero e tantissime difficolt, Mattia - il paziente 1 di Codogno - pu tornare a casa da sua moglie che, tra qualche giorno, diventer mamma.\\n\\nFinalmente qualche bella notizia!\\n\\n#coronavirus #coronavirusitalIa #COVID19italia #Covid_19 #20marzo https://t.co/GeneYm1bxD',\n",
              " 'Dieci giorni di ricovero, la vita consegnata ai medici e affidata a Dio, la sofferenza, il dolore, ma anche la speranza di potercela fare. E la fiducia nella scienza e nella medicina. Dopo essere risultato positivo al Covid-19, monsignor Antonio https://t.co/f5euDjwl6x',\n",
              " 'Coronavirus Milano, Chinatown: Siamo orgogliosi del nostro Paesealtruista e sensibile https://t.co/TLVnMGQwhJ',\n",
              " 'Questa mattina sono arrivate in citt 100mila #mascherine chirurgiche e 200 termometri a infrarossi donate dalla citt di #Guangzhou .#covid19 https://t.co/QIiHNIbRch',\n",
              " 'Comunque, lo dico giusto per dire, stasera #italia1 trasmette #HarryPotter e la pietra filosofale. La #quarantena si fa meno dura e prende esattamente la piega che tutti stavamo aspettando. https://t.co/RZEuKekzMK',\n",
              " 'Quarantena salva\\nIl mio Nintendo DS Lite funziona con inclusi Super Mario Bros, Mario Kart, Animal Crossing: Wild World, The Sims e Cooking Mama 1 e 2',\n",
              " '#coronavirus  Finch non si comincer a sentire notizie di condanne a coloro che non rispettano le norme di limitazione dei contatti sociali la previsione sullandamenti del contagio sar pessimistica!',\n",
              " 'I professionisti dei reparti di #oncologia stanno adottando nuove misure per garantire le #terapie e le adeguate precauzioni per i pazienti in un momento di assoluta fragilit.\\n#nonlasciatecisoli #COVID19\\n\\nhttps://t.co/S6EBVNcf3P',\n",
              " '#iorestoacasa alleniamo mente e corpo per rimanere vivi. Dio proteggici. https://t.co/9vQxKMA87y',\n",
              " 'La mia risposta a  un buon momento questo per comprare azioni / stocks online, per via della pandemia del Coronavirus (COVID-19)? https://t.co/r5DbZO8fyT']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwzPNmpNljfd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "890a3990-ab83-4e39-b297-ba955bb37962"
      },
      "source": [
        "print_tweet(second_week, 'NEUTRAL', 'sentiment_log_under', 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Corriere della Sera: Coronavirus, in Lombardia stop a sport allaperto anche da soli, studi professionali e cantieri.\\nhttps://t.co/7ZGBKHRoxZ',\n",
              " 'Coronavirus: dalla Regione i fondi per la sanificazione delle citt siciliane https://t.co/bIgkxr9CuK https://t.co/C4tpmVCaKC',\n",
              " 'Coronavirus: militari in strada, sindaci e Fontana chiedono altri divieti e chiusure https://t.co/xKy9RA6HAo',\n",
              " 'Un Branco di idioti che metteranno in difficolt il proprio Paese e il mondo #covid19 #coronavirus BBC News - US students party on spring break despite coronavirus\\nhttps://t.co/4J7xOQBjGG',\n",
              " 'Coronavirus. Di Maio: \"Sbloccata l\\'esportazione delle mascherine da Germania-Francia https://t.co/pF8JEPyqrD',\n",
              " 'Coronavirus, De Luca: Se fate feste di laurea, vi mando i carabinieri con lanciafiamme. Sul governo: No a mezze misure. Va chiuso tutto https://t.co/A0Ve6BUhyK',\n",
              " \"Dati coronavirus: \\nContagiati: 35.713\\nMultati perch in strada senza motivo: circa 50.000!!\\nE acclarato in Italia ci stanno pi sciem ca' malat https://t.co/Lve24JHXff\",\n",
              " 'Papa Francesco, Messa a Santa Marta/ Diretta video Tv2000: preghiera per coronavirus https://t.co/SQXpmeS6Od',\n",
              " 'Per vincere il #coronavirus tutti i Paesi Europei devono impegnarsi allo stesso modo. Firma per chiedere un piano congiunto! @thegoodlobbyit #EUcanfightit https://t.co/X1dFRSMiAf',\n",
              " '#Inghilterra #Covid19. Chiusi tutti i locali pubblici, ma il governo prende in carico le paghe retroattivamente | https://t.co/VFMdXwXk0h https://t.co/fbvqk6bQmc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr-vIZpKmJgh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "0a878a38-7f63-4bb9-a5f1-31fec91aef5e"
      },
      "source": [
        "print_tweet(third_week, 'POSITIVE', 'sentiment_log_under', 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[Psicologia] Amore a Distanza (Al Tempo della Quarantena) https://t.co/TbBTSoGoni via @wordpressdotcom',\n",
              " 'Eccola la nostra magnifica #MoleAntonelliana, che illuminata ancora una volta grazie ad @gruppoiren  si prepara a festeggiare con la @twitorino la 75 #FestadellaLiberazione.\\nhttps://t.co/C4mWsEKykw\\n\\n@c_appendino @RubenAbba @chieleon #torino #iorestoacasa @luisacicero #covid19 https://t.co/tYYHnWfpp2',\n",
              " '@INPS_it Buongiorno, vorrei sapere come mai fino a ieri sera mi diceva ATTESA ESITO e questa mattina mi dice che non ci sono domande covid 19 in corso #InpsInAscolto https://t.co/JhcSdAtd1H',\n",
              " 'Un mese fa espressi i miei dubbi. Tra insulti, esser tacciato di fare complottismo e defollow (oggi ringrazio) piovve un mare di melma. Sul #COVID19, e quello che ci hanno raccontato, il Premio Nobel 2008 per la Medicina #Montagner ha le idee chiarissime. \\nAnche lui complottista?',\n",
              " 'Imperia, Coronavirus: Mercato Oneglia, parlano gli ambulanti. \"Bello rivedere...\\nhttps://t.co/ckc3FWn954',\n",
              " \"Nasce 'Respira' , il primo ventilatore polmonare compatto adatto anche per uso domiciliare, grazie alla partnership tra due eccellenze italiane: la Seco di Arezzo e Ibd di Mantova.\\n#COVID19 #coronavirus https://t.co/xDp0iGCfgI\",\n",
              " 'Grazie presidente Zaia - Veneto sempre un passo avanti        Coronavirus e tamponi: la \"disobbedienza\" civile di Zaia ha salvato vite? - Le Iene https://t.co/ouOz9JZerc',\n",
              " 'Fa sempre piacere tuffarsi nella lettura di un libro e restarne rapiti... #libri #books @welikeduel #amigurumi #iorestoacasa #lettura https://t.co/uWRYYqHzLm',\n",
              " \"Ho trovato nella galleria del telefono dei video che ho fatto di nascosto a mio nonno prima che la quarantena iniziasse...e mi sono messa a guardarli,e sto piangendo come una fontana perch vorrei tanto vederlo e spero che tutto questo finisca presto perch non c' la faccio pi-\",\n",
              " 'Coronavirus, Franceschini a FI e FdI: Non bisogna illudere settore del turismo, risposte le do con https://t.co/Vx4nmTzQYs']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhg0Cq7dmJYe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "bb7c6819-df3e-486c-bd4b-bf0cae8fefd4"
      },
      "source": [
        "print_tweet(third_week, 'NEUTRAL', 'sentiment_log_under', 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Al tempo del #COVID19 si parla dello scaglionamento in base allet per il ritorno alla normalit. Vorrei segnalare a Sergio Mattarella, ma non ne avr bisogno, e a @GiuseppeConteIT che gi troppa costituzione  stata adattata ora volete violare lart. 3?',\n",
              " 'A quando il microchip sottopelle per i bambini senza smartphone e senza braccialetto? #coronavirus',\n",
              " 'Sono settimane che non ho aria nei polmoni e non  il corona virus.',\n",
              " \"Il coronavirus si mangia meta' risorse e diritti civili. Ricorda l'euro : da un giorno all'altro tutto organizzato e nessuna informazione ai comuni mortali.\",\n",
              " 'Mara Venier, confessione sulla quarantena: \"Niente coccole con mio marito. Ogni tanto lui allunga una mano, ma io lo freno\" https://t.co/dewQALLHQV',\n",
              " 'Coronavirus, senza il lockdown ci sarebbero stati tra i 600 mila e gli 800 mila morti https://t.co/AR8dT3ksQQ',\n",
              " 'Coronavirus a Messina, fiabe virtuali per i piccoli pazienti del centro @NemoSud \\nhttps://t.co/VzqSfOdrEL @GazzettaDelSud @CentroNemo',\n",
              " 'Selling travel when nobody can travel  Iniziano i nostri corsi virtuali https://t.co/ENifKk7n4h\\nAbbiamo aperto #dfmlab online info@musecomunicazione.it\\n https://t.co/M2KdEjX6BC #hotellerie vendere viaggi... #covid19',\n",
              " 'Mes, il direttore Regling: Prestito? Per lItalia non sar unaltra Grecia. per i Coronabond, serve almeno un anno, intervista #danonperdere al capo del fondo salvastati #percapire @federicofubini \\u2066@L_Economia\\u2069 - del \\u2066@Corriere\\u2069  https://t.co/jZXYxdgNfR',\n",
              " '#Coronavirus. #Indennit #Covid anche a chi fa attivit di emergenza. Per la #Cisl Fp il bonus  da estendere a tutti gli #operatori sanitari che sono esposti quotidianamente.\\n\\n Leggi larticolo su @tusciaweb: https://t.co/sEJ34xr2HU\\n\\n#AiutaChiTiAiuta #Ilmiolavorovale https://t.co/aFybTGti66']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8frLslwO2Vo0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "557e66bb-c256-4fd3-846c-471e0feee184"
      },
      "source": [
        "print_tweet(fourth_week, 'POSITIVE', 'sentiment_log_under', 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' #DonnaSummer @OAODonnaSummer \\nI Remember Yesterday (1977)\\nLa musica che ci piace (ri)ascoltare  (Crazy)\\nFase 2 (quasi bis)  Ai Tempi del Covid - 19  https://t.co/m4NARAaHfx di @YouTube',\n",
              " '@INPS_it Buongiorno, ma i congedi parentali straordinari #covid19 per genitori con figli di et maggiore di 12 anni ma inferiore a 16 anni, sono in numero di 30gg dal 5 marzo o sono illimitati fino a chiusura scuole? Grazie.',\n",
              " 'raga il tendone non si smonta.\\nnessuno smetter di seguire nessuno.\\nattive come sempre quando sar necessario.\\nriprenderemo le nostre vite con annesse tutte le cose che la quarantena ci ha dato.\\nadesso si vedranno i veri fedeli. \\nily, , \\U0001f9e1,   a tutti #circozzi https://t.co/sFuHRCGb2q',\n",
              " 'Nelle Marche ospedale Covid identico a quello \\xa0in Fiera di Milano. Voluto dal governatore Pd, \\xa0vuoto https://t.co/mKlplENpFS',\n",
              " '1 solo nuovo caso positivo al #Covid-19  stato riscontrato nelle ultime 24 ore in #Sardegna, su 1.026 tamponi eseguiti. Nessun decesso  https://t.co/xjdBW0IZLR',\n",
              " \"All'uscita dalla #goldfilm ieri #CanYaman rilascia un'intervista ai media. Parla di #BayYanli del buon rapporto con #zgeGrel, delle false chat con le fans, di Demet Ozdemir e di come ha trasformato il periodo di quarantena in positivo. @canyaman1989  https://t.co/82EHsUHfNj\",\n",
              " \"C' da dire che questa quarantena ci ha insegnato a non essere superficiali, a non pensare sempre al fisico, al taglio di capelli, alla barba....ah no aspet\",\n",
              " '\"Sono ancora convinta che la soluzione sia continuare a credere, negli altri e nel futuro.\" \\n\\nQuella a @MichelaMarzano  una delle undici interviste realizzate durante la #quarantena da @marta_perego per \"Case di carta\", il suo ultimo libro.\\n\\nAcquistalo su https://t.co/Pr4S08WaeD https://t.co/hrxh6NKSPG',\n",
              " 'Il podcast di @senzagiro  per distacco il miglior prodotto audio di questa quarantena! Bravi! Bravissimi tutti! E spero gi in un senza Tour...',\n",
              " 'crocerossa: \"Questo  uno dei servizi pi belli che ho fatto da quando sono in #CroceRossa\". I Volontari di cri_paderno aiutano le persone pi fragili, in isolamento nelle Residenze Sanitarie a causa del rischio #Covid19, a rimanere in contatto con i lor https://t.co/6u0N5NuO0U']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O8YCnaQx2hA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "3b2d456b-adfa-40c9-c56f-1e497fef5d37"
      },
      "source": [
        "print_tweet(fourth_week, 'NEUTRAL', 'sentiment_log_under', 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Molti si chiedono quando ripartir il settore Wedding e quello degli eventi, due di quelli maggiormente colpiti dal Coronavirus\\n\\n#iltarantino #matrimoni #eventi\\n\\n https://t.co/z1pw1bVwxn',\n",
              " 'Buona fine quarantena a tutti!',\n",
              " 'Lavoro%2C una bomba pronta a esplodere: 149 aziende in crisi congelate dal Covid https://t.co/yE6LXngTEb',\n",
              " 'Non solo Boccia boccia il provvedimento ma anche Confindustria #turismo. Le perplessit legittime sono diverse e vengono da tante parti. #covid19 #coronavirus https://t.co/sv2RyllLiP di @ilGiornale',\n",
              " 'Calcio contro il Coronavirus, una magia al giorno/45: Ronaldo e lo stacco che rester nella\\xa0storia https://t.co/ugANoGYoYc',\n",
              " \"#GuidaExpo #news &gt; Le #fiere italiane pronte alla #ripartenza chiedono al #Governo una data certa. @infoaefi ha richiamato lattenzione sull'importanza delle fiere per leconomia: valore per #imprese e creano #lavoro\\n.\\nhttps://t.co/1wHp82V6bC\\n.\\n#coronavirus #covid19 #aefi\",\n",
              " 'Indagine ISTAT sul Covid. Et media delle persone decedute: 80 anni. I morti avevano in media 3 patologie croniche preesistenti. L1% aveva meno di 50 anni',\n",
              " 'Coronavirus, al Regno Unito prime 30 mln dosi del vaccino italo-inglese https://t.co/ZqZOWVdL8p',\n",
              " '#Coronavirus, nessun nuovo contagio in #Calabria. I guariti sono 734 \\n\\nhttps://t.co/YktMHTq2nt',\n",
              " 'Movida e coronavirus: anche a Marsala i giovani che se ne fregano della\\xa0distanza https://t.co/xjA17Ki62J']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHYPCLqCrqpl",
        "colab_type": "text"
      },
      "source": [
        "### LSTM Categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaC6H5HbgBH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi9z7xXdqkFK",
        "colab_type": "text"
      },
      "source": [
        "#### Under-sampling model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX2tAmiTS0-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import models \n",
        "import tensorflow as tf \n",
        "model_under = tf.keras.models.load_model('lstm_category_under.h5')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WOb48_Pqztn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_texts = train_under['clean_text']\n",
        "\n",
        "# tokenizer createad as during the training phase \n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(train_texts)\n",
        "X_train = t.texts_to_sequences(train_texts)\n",
        "\n",
        "labels2numbers = LabelEncoder()\n",
        "y_train = labels2numbers.fit_transform(train_under['sentiment'])\n",
        "\n",
        "k = sorted([len(xx) for xx in X_train])\n",
        "f = k[int(len(k)/100*90)]\n",
        "maxlen = f"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7Wq3xwIkeNE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "d0e2f8dd-5b3b-4eeb-c9e7-86b05f4368b3"
      },
      "source": [
        "# first week \n",
        "X_test = t.texts_to_sequences(first_week.clean_text)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "prediction = model_under.predict(X_test)\n",
        "sentiment = []\n",
        "for pred in prediction: \n",
        "  sentiment.append(labels2numbers.inverse_transform([pred.argmax()])[0])\n",
        "\n",
        "first_week['deep_sentiment_under'] = sentiment\n",
        "first_week_counts = first_week['deep_sentiment_under'].value_counts()\n",
        "\n",
        "w1_deep = PrettyTable(['Model', 'Positive' ,'Negative', 'Neutral'])\n",
        "w1_deep.add_row(['LSTM (under)', \n",
        "           round((first_week_counts[2]/first_week.shape[0] * 100),2), \n",
        "           round((first_week_counts[1]/first_week.shape[0] * 100),2), \n",
        "           round((first_week_counts[0]/first_week.shape[0] * 100),2)])\n",
        "print(w1_deep)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+----------+----------+---------+\n",
            "|    Model     | Positive | Negative | Neutral |\n",
            "+--------------+----------+----------+---------+\n",
            "| LSTM (under) |   6.18   |  29.35   |  64.47  |\n",
            "+--------------+----------+----------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNFYYroTqO4X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "f58c644c-1544-4955-f6b3-7f59f9aceda1"
      },
      "source": [
        "# second week \n",
        "X_test = t.texts_to_sequences(second_week.clean_text)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "prediction = model_under.predict(X_test)\n",
        "sentiment = []\n",
        "for pred in prediction: \n",
        "  sentiment.append(labels2numbers.inverse_transform([pred.argmax()])[0])\n",
        "\n",
        "second_week['deep_sentiment_under'] = sentiment\n",
        "second_week_counts = second_week['deep_sentiment_under'].value_counts()\n",
        "\n",
        "w2_deep = PrettyTable(['Model', 'Positive' ,'Negative', 'Neutral'])\n",
        "w2_deep.add_row(['LSTM (under)', \n",
        "           round((second_week_counts[2]/second_week.shape[0] * 100),2), \n",
        "           round((second_week_counts[1]/second_week.shape[0] * 100),2), \n",
        "           round((second_week_counts[0]/second_week.shape[0] * 100),2)])\n",
        "print(w2_deep)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+----------+----------+---------+\n",
            "|    Model     | Positive | Negative | Neutral |\n",
            "+--------------+----------+----------+---------+\n",
            "| LSTM (under) |   8.96   |  25.84   |  65.21  |\n",
            "+--------------+----------+----------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV3wvh40qdh_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "4df75db8-d616-4764-ba74-6488e93a294b"
      },
      "source": [
        "# third week \n",
        "X_test = t.texts_to_sequences(third_week.clean_text)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "prediction = model_under.predict(X_test)\n",
        "sentiment = []\n",
        "for pred in prediction: \n",
        "  sentiment.append(labels2numbers.inverse_transform([pred.argmax()])[0])\n",
        "\n",
        "third_week['deep_sentiment_under'] = sentiment\n",
        "third_week_counts = third_week['deep_sentiment_under'].value_counts()\n",
        "\n",
        "w3_deep = PrettyTable(['Model', 'Positive' ,'Negative', 'Neutral'])\n",
        "w3_deep.add_row(['LSTM (under)', \n",
        "           round((third_week_counts[2]/third_week.shape[0] * 100),2), \n",
        "           round((third_week_counts[1]/third_week.shape[0] * 100),2), \n",
        "           round((third_week_counts[0]/third_week.shape[0] * 100),2)])\n",
        "print(w3_deep)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+----------+----------+---------+\n",
            "|    Model     | Positive | Negative | Neutral |\n",
            "+--------------+----------+----------+---------+\n",
            "| LSTM (under) |   8.38   |  26.46   |  65.15  |\n",
            "+--------------+----------+----------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDg-VU3zrBVR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "50c4970f-0675-465b-89ab-18f90fdaf02d"
      },
      "source": [
        "# fourth week \n",
        "X_test = t.texts_to_sequences(fourth_week.clean_text)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "prediction = model_under.predict(X_test)\n",
        "sentiment = []\n",
        "for pred in prediction: \n",
        "  sentiment.append(labels2numbers.inverse_transform([pred.argmax()])[0])\n",
        "\n",
        "fourth_week['deep_sentiment_under'] = sentiment\n",
        "fourth_week_counts = fourth_week['deep_sentiment_under'].value_counts()\n",
        "\n",
        "w4_deep = PrettyTable(['Model', 'Positive' ,'Negative', 'Neutral'])\n",
        "w4_deep.add_row(['LSTM (under)', \n",
        "           round((fourth_week_counts[2]/fourth_week.shape[0] * 100),2), \n",
        "           round((fourth_week_counts[1]/fourth_week.shape[0] * 100),2), \n",
        "           round((fourth_week_counts[0]/fourth_week.shape[0] * 100),2)])\n",
        "print(w4_deep)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+----------+----------+---------+\n",
            "|    Model     | Positive | Negative | Neutral |\n",
            "+--------------+----------+----------+---------+\n",
            "| LSTM (under) |   7.67   |  25.36   |  66.97  |\n",
            "+--------------+----------+----------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZbHWQM7r4wL",
        "colab_type": "text"
      },
      "source": [
        "#### Original dataset model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxPdNQIpsHRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import models \n",
        "import tensorflow as tf \n",
        "model_category = tf.keras.models.load_model('lstm_category.h5')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFk8tGOfsL91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_texts = train['clean_text']\n",
        "\n",
        "# tokenizer createad as during the training phase \n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(train_texts)\n",
        "X_train = t.texts_to_sequences(train_texts)\n",
        "\n",
        "labels2numbers = LabelEncoder()\n",
        "y_train = labels2numbers.fit_transform(train['sentiment'])\n",
        "\n",
        "k = sorted([len(xx) for xx in X_train])\n",
        "f = k[int(len(k)/100*90)]\n",
        "maxlen = f"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxcMVd7hsNfi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "bfe7f631-fb16-497d-e725-85899f772cf1"
      },
      "source": [
        "# first week \n",
        "X_test = t.texts_to_sequences(first_week.clean_text)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "prediction = model_category.predict(X_test)\n",
        "sentiment = []\n",
        "for pred in prediction: \n",
        "  sentiment.append(labels2numbers.inverse_transform([pred.argmax()])[0])\n",
        "\n",
        "first_week['deep_sentiment'] = sentiment\n",
        "first_week_counts = first_week['deep_sentiment'].value_counts()\n",
        "\n",
        "w1_deep.add_row(['LSTM (original)', \n",
        "           round((first_week_counts[2]/first_week.shape[0] * 100),2), \n",
        "           round((first_week_counts[1]/first_week.shape[0] * 100),2), \n",
        "           round((first_week_counts[0]/first_week.shape[0] * 100),2)])\n",
        "print(w1_deep)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+----------+----------+---------+\n",
            "|      Model      | Positive | Negative | Neutral |\n",
            "+-----------------+----------+----------+---------+\n",
            "|   LSTM (under)  |   6.18   |  29.35   |  64.47  |\n",
            "| LSTM (original) |   2.73   |   4.8    |  92.48  |\n",
            "+-----------------+----------+----------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TFbtAPisNc1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "e26ee8cd-df04-405e-e082-d39cfe118f04"
      },
      "source": [
        "# second week \n",
        "X_test = t.texts_to_sequences(second_week.clean_text)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "prediction = model_category.predict(X_test)\n",
        "sentiment = []\n",
        "for pred in prediction: \n",
        "  sentiment.append(labels2numbers.inverse_transform([pred.argmax()])[0])\n",
        "\n",
        "second_week['deep_sentiment'] = sentiment\n",
        "second_week_counts = second_week['deep_sentiment'].value_counts()\n",
        "\n",
        "w2_deep.add_row(['LSTM (original)', \n",
        "           round((second_week_counts[2]/second_week.shape[0] * 100),2), \n",
        "           round((second_week_counts[1]/second_week.shape[0] * 100),2), \n",
        "           round((second_week_counts[0]/second_week.shape[0] * 100),2)])\n",
        "print(w2_deep)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+----------+----------+---------+\n",
            "|      Model      | Positive | Negative | Neutral |\n",
            "+-----------------+----------+----------+---------+\n",
            "|   LSTM (under)  |   8.96   |  25.84   |  65.21  |\n",
            "| LSTM (original) |   2.18   |   8.4    |  89.42  |\n",
            "+-----------------+----------+----------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC7ZjzLYsNaS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "fe3707e7-d51b-4a5d-ce1e-8908bd4df23e"
      },
      "source": [
        "# third week \n",
        "X_test = t.texts_to_sequences(third_week.clean_text)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "prediction = model_category.predict(X_test)\n",
        "sentiment = []\n",
        "for pred in prediction: \n",
        "  sentiment.append(labels2numbers.inverse_transform([pred.argmax()])[0])\n",
        "\n",
        "third_week['deep_sentiment'] = sentiment\n",
        "third_week_counts = third_week['deep_sentiment'].value_counts()\n",
        "\n",
        "w3_deep.add_row(['LSTM (original)', \n",
        "           round((third_week_counts[2]/third_week.shape[0] * 100),2), \n",
        "           round((third_week_counts[1]/third_week.shape[0] * 100),2), \n",
        "           round((third_week_counts[0]/third_week.shape[0] * 100),2)])\n",
        "print(w3_deep)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+----------+----------+---------+\n",
            "|      Model      | Positive | Negative | Neutral |\n",
            "+-----------------+----------+----------+---------+\n",
            "|   LSTM (under)  |   8.38   |  26.46   |  65.15  |\n",
            "| LSTM (original) |   1.93   |   6.86   |  91.21  |\n",
            "+-----------------+----------+----------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVlpkse4sNRp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "157bf599-94aa-41ea-f28d-de4cf25d4c5d"
      },
      "source": [
        "# fourth week \n",
        "X_test = t.texts_to_sequences(fourth_week.clean_text)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "prediction = model_category.predict(X_test)\n",
        "sentiment = []\n",
        "for pred in prediction: \n",
        "  sentiment.append(labels2numbers.inverse_transform([pred.argmax()])[0])\n",
        "\n",
        "fourth_week['deep_sentiment'] = sentiment\n",
        "fourth_week_counts = fourth_week['deep_sentiment'].value_counts()\n",
        "\n",
        "w4_deep.add_row(['LSTM (original)', \n",
        "           round((fourth_week_counts[2]/fourth_week.shape[0] * 100),2), \n",
        "           round((fourth_week_counts[1]/fourth_week.shape[0] * 100),2), \n",
        "           round((fourth_week_counts[0]/fourth_week.shape[0] * 100),2)])\n",
        "print(w4_deep)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+----------+----------+---------+\n",
            "|      Model      | Positive | Negative | Neutral |\n",
            "+-----------------+----------+----------+---------+\n",
            "|   LSTM (under)  |   7.67   |  25.36   |  66.97  |\n",
            "| LSTM (original) |   2.11   |   5.75   |  92.14  |\n",
            "+-----------------+----------+----------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxxmKGKHfG8p",
        "colab_type": "text"
      },
      "source": [
        "#### Over-sampling dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkdE51RifC_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import models \n",
        "import tensorflow as tf \n",
        "model_category_over = tf.keras.models.load_model('lstm_category_over.h5')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuSTFcPWhypJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_texts = train['clean_text']\n",
        "\n",
        "# tokenizer createad as during the training phase \n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(train_texts)\n",
        "X_train = t.texts_to_sequences(train_texts)\n",
        "\n",
        "labels2numbers = LabelEncoder()\n",
        "y_train = labels2numbers.fit_transform(train['sentiment'])\n",
        "\n",
        "k = sorted([len(xx) for xx in X_train])\n",
        "f = k[int(len(k)/100*90)]\n",
        "maxlen = f"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1vApohvNhtA9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "430d0c74-2151-4250-d853-7980e437d44c"
      },
      "source": [
        "# first week \n",
        "X_test = t.texts_to_sequences(first_week.clean_text)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "prediction = model_category_over.predict(X_test)\n",
        "sentiment = []\n",
        "for pred in prediction: \n",
        "  sentiment.append(labels2numbers.inverse_transform([pred.argmax()])[0])\n",
        "\n",
        "first_week['deep_sentiment_over'] = sentiment\n",
        "first_week_counts = first_week['deep_sentiment_over'].value_counts()\n",
        "\n",
        "w1_deep.add_row(['LSTM (over)', \n",
        "           round((first_week_counts[2]/first_week.shape[0] * 100),2), \n",
        "           round((first_week_counts[1]/first_week.shape[0] * 100),2), \n",
        "           round((first_week_counts[0]/first_week.shape[0] * 100),2)])\n",
        "print(w1_deep)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+----------+----------+---------+\n",
            "|      Model      | Positive | Negative | Neutral |\n",
            "+-----------------+----------+----------+---------+\n",
            "|   LSTM (under)  |   6.18   |  29.35   |  64.47  |\n",
            "| LSTM (original) |   2.73   |   4.8    |  92.48  |\n",
            "|   LSTM (over)   |   3.62   |   3.91   |  92.47  |\n",
            "+-----------------+----------+----------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZSMxbPmJhtBB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "4e0340c4-a7e7-4cbc-8285-5f57671914a6"
      },
      "source": [
        "# second week \n",
        "X_test = t.texts_to_sequences(second_week.clean_text)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "prediction = model_category_over.predict(X_test)\n",
        "sentiment = []\n",
        "for pred in prediction: \n",
        "  sentiment.append(labels2numbers.inverse_transform([pred.argmax()])[0])\n",
        "\n",
        "second_week['deep_sentiment_over'] = sentiment\n",
        "second_week_counts = second_week['deep_sentiment_over'].value_counts()\n",
        "\n",
        "w2_deep.add_row(['LSTM (over)', \n",
        "           round((second_week_counts[2]/second_week.shape[0] * 100),2), \n",
        "           round((second_week_counts[1]/second_week.shape[0] * 100),2), \n",
        "           round((second_week_counts[0]/second_week.shape[0] * 100),2)])\n",
        "print(w2_deep)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+----------+----------+---------+\n",
            "|      Model      | Positive | Negative | Neutral |\n",
            "+-----------------+----------+----------+---------+\n",
            "|   LSTM (under)  |   8.96   |  25.84   |  65.21  |\n",
            "| LSTM (original) |   2.18   |   8.4    |  89.42  |\n",
            "|   LSTM (over)   |   2.91   |   6.19   |   90.9  |\n",
            "+-----------------+----------+----------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KmgWcDAghtBD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "c46b022e-1eb9-459c-a0a9-629105c33d71"
      },
      "source": [
        "# third week \n",
        "X_test = t.texts_to_sequences(third_week.clean_text)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "prediction = model_category_over.predict(X_test)\n",
        "sentiment = []\n",
        "for pred in prediction: \n",
        "  sentiment.append(labels2numbers.inverse_transform([pred.argmax()])[0])\n",
        "\n",
        "third_week['deep_sentiment_over'] = sentiment\n",
        "third_week_counts = third_week['deep_sentiment_over'].value_counts()\n",
        "\n",
        "w3_deep.add_row(['LSTM (over)', \n",
        "           round((third_week_counts[2]/third_week.shape[0] * 100),2), \n",
        "           round((third_week_counts[1]/third_week.shape[0] * 100),2), \n",
        "           round((third_week_counts[0]/third_week.shape[0] * 100),2)])\n",
        "print(w3_deep)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+----------+----------+---------+\n",
            "|      Model      | Positive | Negative | Neutral |\n",
            "+-----------------+----------+----------+---------+\n",
            "|   LSTM (under)  |   8.38   |  26.46   |  65.15  |\n",
            "| LSTM (original) |   1.93   |   6.86   |  91.21  |\n",
            "|   LSTM (over)   |   2.58   |   5.65   |  91.77  |\n",
            "+-----------------+----------+----------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LGIKhXLThtBG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "0c46daf6-728f-46b0-b924-de9428a96f47"
      },
      "source": [
        "# fourth week \n",
        "X_test = t.texts_to_sequences(fourth_week.clean_text)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "prediction = model_category_over.predict(X_test)\n",
        "sentiment = []\n",
        "for pred in prediction: \n",
        "  sentiment.append(labels2numbers.inverse_transform([pred.argmax()])[0])\n",
        "\n",
        "fourth_week['deep_sentiment_over'] = sentiment\n",
        "fourth_week_counts = fourth_week['deep_sentiment_over'].value_counts()\n",
        "\n",
        "w4_deep.add_row(['LSTM (over)', \n",
        "           round((fourth_week_counts[2]/fourth_week.shape[0] * 100),2), \n",
        "           round((fourth_week_counts[1]/fourth_week.shape[0] * 100),2), \n",
        "           round((fourth_week_counts[0]/fourth_week.shape[0] * 100),2)])\n",
        "print(w4_deep)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+----------+----------+---------+\n",
            "|      Model      | Positive | Negative | Neutral |\n",
            "+-----------------+----------+----------+---------+\n",
            "|   LSTM (under)  |   7.67   |  25.36   |  66.97  |\n",
            "| LSTM (original) |   2.11   |   5.75   |  92.14  |\n",
            "|   LSTM (over)   |   2.55   |   4.84   |  92.61  |\n",
            "+-----------------+----------+----------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9JjsPCZtsFN",
        "colab_type": "text"
      },
      "source": [
        "#### Print tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_IIVb4KsdvN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "7de1474c-908a-474a-fc21-26ac1ecbd35d"
      },
      "source": [
        "print_tweet(first_week, 'NEGATIVE', 'deep_sentiment_under', 10)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Coronavirus, il piano di Trump: \\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200buna task force \\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200be linvito alla calma https://t.co/8WQ7tUEejh https://t.co/M0nGxFT7eV',\n",
              " \"Per alcuni temerari il #COVID19  l'anticorpo della Terra che si difende dalle devastazioni climatiche e inquinamento degli umani.\",\n",
              " 'GUALTIERI MINISTRO DELLECONOMIA ha comunicato che a causa del CORONAVIRUS\\n- I COMUNI DOVE LECONOMIA SI  FERMATA AVRANNO UNA SOSPENSIONE DEL PAGAMENTO DELLE TASSE E BOLLETTE\\n- INVECE PER TUTTA LITALIA VIENE TOLTO IL PAGAMENTO DI TASSE E CONTRIBUTI A TUTTE LE AZIENDE TURISTICHE',\n",
              " 'Dopo la psicosi da virus, emerge che laspetto pi grave non  quello della salute pubblica ma quella economica... Coronavirus, Burioni e la psicosi: Non  un raffreddore ma nemmeno la peste. Mi scuso con Gismondo, la collega del Sacco #agorarai',\n",
              " '#Coronavirus : a #Palermo #cinesi chiudono negozi per paura di essere contagiati dai turisti\\n\\nCari amici cinesi, questa  una barzelletta. State mettendo in ginocchio lItalia  fate dellumorismo? Fate una cosa, chiudete per sempre e andate altrove.  https://t.co/Fz3TlQWqd8',\n",
              " 'Spediscono nelle buste di plastica e fanno FCFS a Milano con emergenza corona virus, i miei geni https://t.co/VxBYaWaDZl',\n",
              " 'Non mi dite che non esistono le  caratteristiche di genere. Tutti i maschi che conosco reputano eccessiva la preoccupazione isterica per il #coronavirus e sono preoccupati per le aziende. Tutte le donne se ne fregano delleconomia, preoccupate + o - istericamente del contagio.',\n",
              " '#coronavirus 3 giorni scuole chiuse a Napoli per igienizzazione e sanificazione ma la citt continua ad essere sporca. Incoerenze da #coronavirusitalianews    https://t.co/2hOsesc2d4',\n",
              " 'il coronavirus ha scelto proprio litalia perch ha visto che siamo un popolo di deficienti che guardano Barbara DUrso e ha capito che meritiamo lestinzione',\n",
              " \"#CoronaVirusitaly \\nL'epidemia si allarga a tutta l'Italia\\n\\nUltim'ora 08.15 @repubblica \\nCoronavirus, due nuovi casi in Italia: a Firenze e Palermo\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKHaqb58FGgy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "b61ee9de-f8d3-4c64-dfe0-1380d4794359"
      },
      "source": [
        "print_tweet(fourth_week, 'NEUTRAL', 'deep_sentiment_under', 10)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Coronavirus, in Lombardia 84.844 casi. Crescono i guariti e calano i ricoveri https://t.co/Kpz7xPad6k',\n",
              " 'Coronavirus. Radiografia al torace predice ricovero e intubazione https://t.co/0IQFWNvVnN',\n",
              " 'Coronavirus a Reggio Calabria, nessun nuovo contagiato #calabrianotizie #newscalabria https://t.co/86fWnxyCrF',\n",
              " 'Coronavirus. Bollettino Regione Calabria, +0 positivi rispetto a ieri https://t.co/84Zc5DJYWv',\n",
              " 'CORONAVIRUS, ASL VITERBO: UN CASO ACCERTATO NELLA GIORNATA DI OGGI A BELCOLLE https://t.co/PZNtirdXVj di @lacitta',\n",
              " 'CORONAVIRUS: IL BOLLETTINO/ A Pozzuoli nessun contagiato da nove giorni: anche oggi zero\\xa0positivi https://t.co/lYB5jFt9U0',\n",
              " 'A #Verona il 95% della popolazione non ha contratto il coronavirus https://t.co/W79GgyGja0',\n",
              " 'Quelli che... in tempi di #quarantena da #pandemia devono stare a casa e non sapendo come passare tempo picchiano le mogli che devono stare a casa anche loro... OH YEAH! \\n[mezza cit. Jannacci]\\nSembra una brutta battuta ma i dati dicono sia davvero cos... #portaaporta #Lamorgese',\n",
              " \"Gli ultimi dati del Covid 19 ci dice che l'84% dei positivi non ha sintomi o sintomi lievi.Quindi solo il 16% si ammala gravemente.Allora di che si sta parlando?????\",\n",
              " 'Spadafora: \"Il 28 maggio riunione con @FIGC e @SerieA, decideremo il futuro del campionato\"\\n\\n#lungavitaalcalcio #LVAC #SerieA #coronavirus #COVID19 https://t.co/PwpcOhXFOP']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itQmcxtmtKGg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "d2574a41-69dc-42a3-d34f-5d155e83fb91"
      },
      "source": [
        "print_tweet(fourth_week, 'POSITIVE', 'deep_sentiment_under', 10)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"L'Italia ha fornito 800 risposte all'indagine che i ricercatori europei hanno diffuso in 23 Nazioni su #alcol e #coronavirus.Ne servono 2000,il ink al questionario :\\nhttps://t.co/ptOddgZukJ \\nCOMPILATE &amp; CONDIVIDETE, Grazie ! \\n@istsupsan  @MinisteroSalute  https://t.co/MlTAd3HzIu\",\n",
              " 'Coronavirus, al Regno Unito prime 30 mln dosi del vaccino italo-inglese https://t.co/flybmmdE0T',\n",
              " 'Questa famiglia  nata per sostenerle e per la loro musica, la quarantena sar finita, si scriver di meno, ma una famiglia  sempre una famiglia. Loro ci accomunano e le far piacere vedere questa famiglia unita che le sostiene e saper di poter contare su di noi. #circozzi',\n",
              " ' In #ValledAosta nessun nuovo caso positivo nelle ultime 24 ore. Il totale, quindi, resta a 1.177 e 86 attualmente positivi. Decessi totali: 143. In terapia intensiva: 2. In isolamento domiciliare: 61. #covid19 #coronavirus',\n",
              " 'CORONAVIRUS: Sale a 9 morti in Gibuti, 30 in Yemen, 55 in Mali, 57 in Ciad, 61 in Somalia, 233 negli Emirati Arabi Uniti, 279 in Israele, 304 in Repubblica Ceca, 339 in Sudafrica e 962 in Polonia: In totale sono 325.627 morti https://t.co/Vu0hg9KfoB',\n",
              " 'Raga ma solo a me va in crush Facebook? #facebookdown #COVID19',\n",
              " 'Dai valore alla gioia e agli eventi belli: non rinunciare ai giorni di festa... in sicurezza\\n#iorestoacasa #palloncini #partyacasa #festaincasa #palloncini #party #auguri #compleanno #festa #kitfesta https://t.co/xYgBvSWv2J',\n",
              " 'I ricatti delle Nazioni unite durante il coronavirus https://t.co/UdjRL9ZjmD',\n",
              " 'Comunicazione istituzionale e giornalistica al tempo del\\xa0Covid https://t.co/sxKcaL6QaN',\n",
              " 'Coronavirus, il primo aggiornamento di giornata su contagi che tornano a salire https://t.co/sW7IjUIvO3']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    }
  ]
}